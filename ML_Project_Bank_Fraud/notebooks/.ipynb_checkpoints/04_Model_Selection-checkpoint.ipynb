{
 "cells": [
  {
   "attachments": {
    "ed2b78cf-28e8-4b9f-b0a7-7a33715c6677.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "407f8ec0-ed64-4bd5-9d10-ca5482ce7b06",
   "metadata": {},
   "source": [
    "![image.png](attachment:ed2b78cf-28e8-4b9f-b0a7-7a33715c6677.png)\n",
    "\n",
    "# Máster en Data Science - Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1513189-4152-4cf6-a597-f977ab246450",
   "metadata": {},
   "source": [
    "# Predicción de fraude mediante el uso de modelos de Machine Learning\n",
    "##### <font color='dodgerblue' face='Montserrat'>Autor: Rodrigo Fernandez Campos</font>\n",
    "## DataSet: Bank Account Fraud Dataset Suite (NeurIPS 2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a09322-147f-44ca-b5ea-77e1e8add901",
   "metadata": {},
   "source": [
    "# <font size=25><b>Comparación y seleccion de Modelos</b></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "dc0b4ffb-0b89-4773-847b-f3d5a886cb6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from termcolor import colored, cprint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel, RFE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm\n",
    "from lightgbm.sklearn import LGBMClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "#from skopt import BayesSearchCV\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score,average_precision_score, precision_recall_curve, roc_curve, auc, recall_score, precision_score, confusion_matrix, f1_score\n",
    "\n",
    "import pickle\n",
    "from joblib import dump, load\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bf12c4-4755-441b-beba-a508611679aa",
   "metadata": {},
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec3b7952-e55b-405d-a06a-cb3e39bbe766",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append('../src/')\n",
    "import functions_rfc as fr\n",
    "sys.path.remove('../src/')\n",
    "\n",
    "### Constantes:\n",
    "seed=10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd26a6aa-3848-4a18-a679-e645ae18d797",
   "metadata": {},
   "source": [
    "***\n",
    "# Importo y preparo los datasets\n",
    "\n",
    "## Importo datasets procesados con anterioridad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6aec855-a0b9-4026-8329-a23c46e46517",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>name_email_similarity</th>\n",
       "      <th>prev_address_months_count</th>\n",
       "      <th>current_address_months_count</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>days_since_request</th>\n",
       "      <th>intended_balcon_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>zip_count_4w</th>\n",
       "      <th>velocity_6h</th>\n",
       "      <th>velocity_24h</th>\n",
       "      <th>velocity_4w</th>\n",
       "      <th>bank_branch_count_8w</th>\n",
       "      <th>date_of_birth_distinct_emails_4w</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>credit_risk_score</th>\n",
       "      <th>email_is_free</th>\n",
       "      <th>housing_status</th>\n",
       "      <th>phone_home_valid</th>\n",
       "      <th>phone_mobile_valid</th>\n",
       "      <th>bank_months_count</th>\n",
       "      <th>has_other_cards</th>\n",
       "      <th>proposed_credit_limit</th>\n",
       "      <th>foreign_request</th>\n",
       "      <th>source</th>\n",
       "      <th>session_length_in_minutes</th>\n",
       "      <th>device_os_other</th>\n",
       "      <th>device_os_linux</th>\n",
       "      <th>device_os_windows</th>\n",
       "      <th>device_os_macintosh</th>\n",
       "      <th>device_os_x11</th>\n",
       "      <th>keep_alive_session</th>\n",
       "      <th>device_distinct_emails_8w</th>\n",
       "      <th>month</th>\n",
       "      <th>fraud_bool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.433984</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>0.020608</td>\n",
       "      <td>49.172739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>954</td>\n",
       "      <td>5137.541683</td>\n",
       "      <td>2712.051960</td>\n",
       "      <td>4240.496920</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.396148</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.712826</td>\n",
       "      <td>-1</td>\n",
       "      <td>97</td>\n",
       "      <td>50</td>\n",
       "      <td>0.024353</td>\n",
       "      <td>-1.091855</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1108</td>\n",
       "      <td>4370.169334</td>\n",
       "      <td>3097.535634</td>\n",
       "      <td>4383.873312</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.100053</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.222290</td>\n",
       "      <td>32</td>\n",
       "      <td>115</td>\n",
       "      <td>30</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>-1.067640</td>\n",
       "      <td>2.0</td>\n",
       "      <td>266</td>\n",
       "      <td>7168.731474</td>\n",
       "      <td>2865.219877</td>\n",
       "      <td>4207.649556</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.369306</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.476667</td>\n",
       "      <td>-1</td>\n",
       "      <td>375</td>\n",
       "      <td>40</td>\n",
       "      <td>0.020157</td>\n",
       "      <td>-0.930885</td>\n",
       "      <td>2.0</td>\n",
       "      <td>962</td>\n",
       "      <td>4761.030105</td>\n",
       "      <td>6249.502233</td>\n",
       "      <td>6013.337906</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>245</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31.700024</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.506995</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.007662</td>\n",
       "      <td>-0.698526</td>\n",
       "      <td>2.0</td>\n",
       "      <td>874</td>\n",
       "      <td>8823.184279</td>\n",
       "      <td>6315.937497</td>\n",
       "      <td>5653.839202</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.592456</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   income  name_email_similarity  prev_address_months_count  \\\n",
       "0     0.8               0.433984                         54   \n",
       "1     0.1               0.712826                         -1   \n",
       "2     0.4               0.222290                         32   \n",
       "3     0.7               0.476667                         -1   \n",
       "4     0.1               0.506995                         11   \n",
       "\n",
       "   current_address_months_count  customer_age  days_since_request  \\\n",
       "0                             9            30            0.020608   \n",
       "1                            97            50            0.024353   \n",
       "2                           115            30            0.002837   \n",
       "3                           375            40            0.020157   \n",
       "4                            10            20            0.007662   \n",
       "\n",
       "   intended_balcon_amount  payment_type  zip_count_4w  velocity_6h  \\\n",
       "0               49.172739           0.0           954  5137.541683   \n",
       "1               -1.091855           1.0          1108  4370.169334   \n",
       "2               -1.067640           2.0           266  7168.731474   \n",
       "3               -0.930885           2.0           962  4761.030105   \n",
       "4               -0.698526           2.0           874  8823.184279   \n",
       "\n",
       "   velocity_24h  velocity_4w  bank_branch_count_8w  \\\n",
       "0   2712.051960  4240.496920                     2   \n",
       "1   3097.535634  4383.873312                     0   \n",
       "2   2865.219877  4207.649556                     0   \n",
       "3   6249.502233  6013.337906                     0   \n",
       "4   6315.937497  5653.839202                     0   \n",
       "\n",
       "   date_of_birth_distinct_emails_4w  employment_status  credit_risk_score  \\\n",
       "0                                11                0.0                286   \n",
       "1                                 6                0.0                132   \n",
       "2                                11                0.0                171   \n",
       "3                                 8                0.0                245   \n",
       "4                                13                3.0                 20   \n",
       "\n",
       "   email_is_free  housing_status  phone_home_valid  phone_mobile_valid  \\\n",
       "0              0             0.0                 0                   1   \n",
       "1              0             1.0                 1                   1   \n",
       "2              0             4.0                 0                   1   \n",
       "3              1             0.0                 0                   1   \n",
       "4              0             2.0                 0                   1   \n",
       "\n",
       "   bank_months_count  has_other_cards  proposed_credit_limit  foreign_request  \\\n",
       "0                  1                1                 1000.0                0   \n",
       "1                 28                1                  200.0                0   \n",
       "2                 -1                1                  200.0                0   \n",
       "3                 -1                1                 1500.0                1   \n",
       "4                 -1                0                  200.0                0   \n",
       "\n",
       "   source  session_length_in_minutes  device_os_other  device_os_linux  \\\n",
       "0       0                  14.396148                1                0   \n",
       "1       0                   4.100053                1                0   \n",
       "2       0                   2.369306                1                0   \n",
       "3       0                  31.700024                0                1   \n",
       "4       0                   0.592456                0                1   \n",
       "\n",
       "   device_os_windows  device_os_macintosh  device_os_x11  keep_alive_session  \\\n",
       "0                  0                    0              0                   0   \n",
       "1                  0                    0              0                   0   \n",
       "2                  0                    0              0                   0   \n",
       "3                  0                    0              0                   1   \n",
       "4                  0                    0              0                   1   \n",
       "\n",
       "   device_distinct_emails_8w  month  fraud_bool  \n",
       "0                          1      6           0  \n",
       "1                          1      6           0  \n",
       "2                          1      5           0  \n",
       "3                          1      1           0  \n",
       "4                          1      2           0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fraud_train = pd.read_csv('../data/processed/df_train_ready_to_model.csv')\n",
    "df_fraud_test = pd.read_csv('../data/processed/df_test_ready_to_model.csv')\n",
    "\n",
    "df_fraud_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ab764a-f2a4-4da9-a117-38bdaabd07a7",
   "metadata": {},
   "source": [
    "Selecciono solo las variables elegidas en el último procesamiento del notebook anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b52d72e9-687b-418c-ae72-da421d3df18c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700000, 30)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fraud_train_cut = df_fraud_train.drop(['source','velocity_24h','velocity_6h','phone_mobile_valid', 'bank_months_count'], axis=1)\n",
    "df_fraud_test_cut = df_fraud_test.drop(['source','velocity_24h','velocity_6h','phone_mobile_valid', 'bank_months_count'], axis=1)\n",
    "\n",
    "df_fraud_train_cut.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf6c31c-d49f-4b89-9b69-0dc6cdef12b5",
   "metadata": {},
   "source": [
    "Separo en Train y Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d35679f6-6736-4276-b468-e2c7242ade49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = df_fraud_train_cut.drop('fraud_bool', axis=1)\n",
    "y_train = df_fraud_train_cut['fraud_bool']\n",
    "X_test = df_fraud_test_cut.drop('fraud_bool', axis=1)\n",
    "y_test = df_fraud_test_cut['fraud_bool']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a667516-9181-4f4f-8529-fdb6df6b7cca",
   "metadata": {},
   "source": [
    "## Separación en train y validación estratificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4786a54-9e2d-4d17-9be6-3bafdb950244",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df_fraud_train_cut.drop('fraud_bool',axis=1)\n",
    "                                                  ,df_fraud_train_cut['fraud_bool']\n",
    "                                                  ,stratify=df_fraud_train_cut['fraud_bool']\n",
    "                                                  ,test_size=0.3\n",
    "                                                  ,random_state=seed)\n",
    "\n",
    "X_train_complete, X_val_complete, y_train_complete, y_val_complete = train_test_split(df_fraud_train.drop('fraud_bool',axis=1)\n",
    "                                                                                      ,df_fraud_train['fraud_bool']\n",
    "                                                                                      ,stratify=df_fraud_train['fraud_bool']\n",
    "                                                                                      ,test_size=0.3\n",
    "                                                                                      ,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44b58133-3199-42e8-8a29-7e444327fbfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((490000, 29), (210000, 29), (490000, 34), (210000, 34))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, X_train_complete.shape, X_val_complete.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b35fc9-aed9-4746-b519-b34674cb35ae",
   "metadata": {},
   "source": [
    "### Realizo el escalado para utilizar al aplicar el modelo de Regresión Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5dabb89-ab38-4241-bf30-0c73535c1bd9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>name_email_similarity</th>\n",
       "      <th>prev_address_months_count</th>\n",
       "      <th>current_address_months_count</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>days_since_request</th>\n",
       "      <th>intended_balcon_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>zip_count_4w</th>\n",
       "      <th>velocity_4w</th>\n",
       "      <th>bank_branch_count_8w</th>\n",
       "      <th>date_of_birth_distinct_emails_4w</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>credit_risk_score</th>\n",
       "      <th>email_is_free</th>\n",
       "      <th>housing_status</th>\n",
       "      <th>phone_home_valid</th>\n",
       "      <th>has_other_cards</th>\n",
       "      <th>proposed_credit_limit</th>\n",
       "      <th>foreign_request</th>\n",
       "      <th>session_length_in_minutes</th>\n",
       "      <th>device_os_other</th>\n",
       "      <th>device_os_linux</th>\n",
       "      <th>device_os_windows</th>\n",
       "      <th>device_os_macintosh</th>\n",
       "      <th>device_os_x11</th>\n",
       "      <th>keep_alive_session</th>\n",
       "      <th>device_distinct_emails_8w</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>599278</th>\n",
       "      <td>-0.906378</td>\n",
       "      <td>-1.141368</td>\n",
       "      <td>-0.107470</td>\n",
       "      <td>-0.753237</td>\n",
       "      <td>-0.306349</td>\n",
       "      <td>-0.187361</td>\n",
       "      <td>-0.480608</td>\n",
       "      <td>-0.239490</td>\n",
       "      <td>-0.526812</td>\n",
       "      <td>1.239599</td>\n",
       "      <td>4.292476</td>\n",
       "      <td>0.496493</td>\n",
       "      <td>0.308335</td>\n",
       "      <td>0.259751</td>\n",
       "      <td>0.940482</td>\n",
       "      <td>0.180225</td>\n",
       "      <td>-0.846629</td>\n",
       "      <td>-0.535305</td>\n",
       "      <td>-0.030835</td>\n",
       "      <td>-0.161577</td>\n",
       "      <td>-0.337002</td>\n",
       "      <td>-0.721847</td>\n",
       "      <td>1.417951</td>\n",
       "      <td>-0.598906</td>\n",
       "      <td>-0.238795</td>\n",
       "      <td>-0.085935</td>\n",
       "      <td>-1.166552</td>\n",
       "      <td>-0.101765</td>\n",
       "      <td>-0.129402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499849</th>\n",
       "      <td>1.160536</td>\n",
       "      <td>1.227288</td>\n",
       "      <td>-0.402094</td>\n",
       "      <td>0.253942</td>\n",
       "      <td>0.524904</td>\n",
       "      <td>-0.188845</td>\n",
       "      <td>-0.506226</td>\n",
       "      <td>0.793958</td>\n",
       "      <td>1.384972</td>\n",
       "      <td>-0.595162</td>\n",
       "      <td>-0.400956</td>\n",
       "      <td>0.098949</td>\n",
       "      <td>-0.473747</td>\n",
       "      <td>0.302832</td>\n",
       "      <td>-1.063284</td>\n",
       "      <td>-0.607893</td>\n",
       "      <td>1.181155</td>\n",
       "      <td>1.868093</td>\n",
       "      <td>-0.646885</td>\n",
       "      <td>-0.161577</td>\n",
       "      <td>0.428755</td>\n",
       "      <td>-0.721847</td>\n",
       "      <td>-0.705243</td>\n",
       "      <td>-0.598906</td>\n",
       "      <td>4.187688</td>\n",
       "      <td>-0.085935</td>\n",
       "      <td>0.857227</td>\n",
       "      <td>-0.101765</td>\n",
       "      <td>0.775534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345337</th>\n",
       "      <td>-1.595349</td>\n",
       "      <td>1.292729</td>\n",
       "      <td>0.209817</td>\n",
       "      <td>-0.787187</td>\n",
       "      <td>-1.137602</td>\n",
       "      <td>-0.189010</td>\n",
       "      <td>-0.508535</td>\n",
       "      <td>-0.239490</td>\n",
       "      <td>0.148930</td>\n",
       "      <td>-0.242573</td>\n",
       "      <td>-0.396598</td>\n",
       "      <td>1.689126</td>\n",
       "      <td>-0.473747</td>\n",
       "      <td>0.460797</td>\n",
       "      <td>-1.063284</td>\n",
       "      <td>-0.607893</td>\n",
       "      <td>1.181155</td>\n",
       "      <td>-0.535305</td>\n",
       "      <td>-0.010300</td>\n",
       "      <td>-0.161577</td>\n",
       "      <td>-0.332120</td>\n",
       "      <td>1.385334</td>\n",
       "      <td>-0.705243</td>\n",
       "      <td>-0.598906</td>\n",
       "      <td>-0.238795</td>\n",
       "      <td>-0.085935</td>\n",
       "      <td>-1.166552</td>\n",
       "      <td>-0.101765</td>\n",
       "      <td>-0.129402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571314</th>\n",
       "      <td>-1.595349</td>\n",
       "      <td>-0.058074</td>\n",
       "      <td>-0.402094</td>\n",
       "      <td>-0.300572</td>\n",
       "      <td>0.524904</td>\n",
       "      <td>-0.189629</td>\n",
       "      <td>-0.503390</td>\n",
       "      <td>0.793958</td>\n",
       "      <td>-0.220290</td>\n",
       "      <td>0.473835</td>\n",
       "      <td>-0.400956</td>\n",
       "      <td>-0.298595</td>\n",
       "      <td>-0.473747</td>\n",
       "      <td>-0.788563</td>\n",
       "      <td>0.940482</td>\n",
       "      <td>-0.607893</td>\n",
       "      <td>-0.846629</td>\n",
       "      <td>-0.535305</td>\n",
       "      <td>-0.646885</td>\n",
       "      <td>-0.161577</td>\n",
       "      <td>2.296500</td>\n",
       "      <td>1.385334</td>\n",
       "      <td>-0.705243</td>\n",
       "      <td>-0.598906</td>\n",
       "      <td>-0.238795</td>\n",
       "      <td>-0.085935</td>\n",
       "      <td>-1.166552</td>\n",
       "      <td>-0.101765</td>\n",
       "      <td>-1.034339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379586</th>\n",
       "      <td>-0.561893</td>\n",
       "      <td>-0.499498</td>\n",
       "      <td>-0.130133</td>\n",
       "      <td>-0.877720</td>\n",
       "      <td>-0.306349</td>\n",
       "      <td>-0.186727</td>\n",
       "      <td>-0.476766</td>\n",
       "      <td>1.827405</td>\n",
       "      <td>1.479517</td>\n",
       "      <td>1.158247</td>\n",
       "      <td>-0.322514</td>\n",
       "      <td>1.291582</td>\n",
       "      <td>-0.473747</td>\n",
       "      <td>0.776728</td>\n",
       "      <td>0.940482</td>\n",
       "      <td>0.180225</td>\n",
       "      <td>-0.846629</td>\n",
       "      <td>-0.535305</td>\n",
       "      <td>2.022667</td>\n",
       "      <td>-0.161577</td>\n",
       "      <td>-0.130286</td>\n",
       "      <td>1.385334</td>\n",
       "      <td>-0.705243</td>\n",
       "      <td>-0.598906</td>\n",
       "      <td>-0.238795</td>\n",
       "      <td>-0.085935</td>\n",
       "      <td>-1.166552</td>\n",
       "      <td>-0.101765</td>\n",
       "      <td>-0.581871</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          income  name_email_similarity  prev_address_months_count  \\\n",
       "599278 -0.906378              -1.141368                  -0.107470   \n",
       "499849  1.160536               1.227288                  -0.402094   \n",
       "345337 -1.595349               1.292729                   0.209817   \n",
       "571314 -1.595349              -0.058074                  -0.402094   \n",
       "379586 -0.561893              -0.499498                  -0.130133   \n",
       "\n",
       "        current_address_months_count  customer_age  days_since_request  \\\n",
       "599278                     -0.753237     -0.306349           -0.187361   \n",
       "499849                      0.253942      0.524904           -0.188845   \n",
       "345337                     -0.787187     -1.137602           -0.189010   \n",
       "571314                     -0.300572      0.524904           -0.189629   \n",
       "379586                     -0.877720     -0.306349           -0.186727   \n",
       "\n",
       "        intended_balcon_amount  payment_type  zip_count_4w  velocity_4w  \\\n",
       "599278               -0.480608     -0.239490     -0.526812     1.239599   \n",
       "499849               -0.506226      0.793958      1.384972    -0.595162   \n",
       "345337               -0.508535     -0.239490      0.148930    -0.242573   \n",
       "571314               -0.503390      0.793958     -0.220290     0.473835   \n",
       "379586               -0.476766      1.827405      1.479517     1.158247   \n",
       "\n",
       "        bank_branch_count_8w  date_of_birth_distinct_emails_4w  \\\n",
       "599278              4.292476                          0.496493   \n",
       "499849             -0.400956                          0.098949   \n",
       "345337             -0.396598                          1.689126   \n",
       "571314             -0.400956                         -0.298595   \n",
       "379586             -0.322514                          1.291582   \n",
       "\n",
       "        employment_status  credit_risk_score  email_is_free  housing_status  \\\n",
       "599278           0.308335           0.259751       0.940482        0.180225   \n",
       "499849          -0.473747           0.302832      -1.063284       -0.607893   \n",
       "345337          -0.473747           0.460797      -1.063284       -0.607893   \n",
       "571314          -0.473747          -0.788563       0.940482       -0.607893   \n",
       "379586          -0.473747           0.776728       0.940482        0.180225   \n",
       "\n",
       "        phone_home_valid  has_other_cards  proposed_credit_limit  \\\n",
       "599278         -0.846629        -0.535305              -0.030835   \n",
       "499849          1.181155         1.868093              -0.646885   \n",
       "345337          1.181155        -0.535305              -0.010300   \n",
       "571314         -0.846629        -0.535305              -0.646885   \n",
       "379586         -0.846629        -0.535305               2.022667   \n",
       "\n",
       "        foreign_request  session_length_in_minutes  device_os_other  \\\n",
       "599278        -0.161577                  -0.337002        -0.721847   \n",
       "499849        -0.161577                   0.428755        -0.721847   \n",
       "345337        -0.161577                  -0.332120         1.385334   \n",
       "571314        -0.161577                   2.296500         1.385334   \n",
       "379586        -0.161577                  -0.130286         1.385334   \n",
       "\n",
       "        device_os_linux  device_os_windows  device_os_macintosh  \\\n",
       "599278         1.417951          -0.598906            -0.238795   \n",
       "499849        -0.705243          -0.598906             4.187688   \n",
       "345337        -0.705243          -0.598906            -0.238795   \n",
       "571314        -0.705243          -0.598906            -0.238795   \n",
       "379586        -0.705243          -0.598906            -0.238795   \n",
       "\n",
       "        device_os_x11  keep_alive_session  device_distinct_emails_8w     month  \n",
       "599278      -0.085935           -1.166552                  -0.101765 -0.129402  \n",
       "499849      -0.085935            0.857227                  -0.101765  0.775534  \n",
       "345337      -0.085935           -1.166552                  -0.101765 -0.129402  \n",
       "571314      -0.085935           -1.166552                  -0.101765 -1.034339  \n",
       "379586      -0.085935           -1.166552                  -0.101765 -0.581871  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "model_scaled = scaler.fit(X_train)\n",
    "X_train_scaled = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns, index=X_train.index)\n",
    "X_val_scaled = pd.DataFrame(scaler.transform(X_val), columns=X_val.columns, index=X_val.index)\n",
    "\n",
    "X_train_scaled.head() # muestro uno de ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddebe22d-6d14-4631-a8d6-fba486d16a08",
   "metadata": {},
   "source": [
    "***\n",
    "# Unsersampling + Oversampling\n",
    "\n",
    "Investigando en internet me he topado con una técnica que me parece interesante, que es una combinación proporcional de undersampling y oversampling. He decidido probarlo mediante la aplicación de un Pipeline en donde se aplican secuencialmente las técnicas.\n",
    "\n",
    "Me parece una aplicación acertada para casos como el de este dataset en donde los datos están extremadamente desbalanceados, al punto de que un undersampling aplicado directamente eliminaría una cantidad demasiado alta de información, mientras que un oversampling podría generar un sesgo por la cantidad enorme de datos sintéticos a generar. Es por eso que un acercamiento entre ambos parece una solución interesante, al menos sobre el papel.\n",
    "\n",
    "Existen dentro de Imbalanced-Learning de SKL dos funciones con una combinación interna de oversampling y undersampling, pero al probarlas no parecen estar optimizadas y el costo computacional que me requieren es demasiado alto, por eso generaré y aplicaré mi propio Pipeline manualmente.\n",
    "\n",
    "Entonces, para lidiar con el desbalanceo terminaré aplicando:\n",
    "\n",
    "1. Split estatificado (SE) --> (realizado en Notebook 02)\n",
    "2. RandomUnderSampling\n",
    "3. SMOTE OverSampling\n",
    "4. Pipeline con sampling mix --> (SMOTE OverSampling + Random UnderSampling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8a93cfa-5293-4c40-8e91-9d9f107600bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((490000, 29),\n",
       " fraud_bool\n",
       " 0    484596\n",
       " 1      5404\n",
       " Name: count, dtype: int64,\n",
       " fraud_bool\n",
       " 0    0.988971\n",
       " 1    0.011029\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El tamaño y distribución actual del DataSet de train son los siguientes:\n",
    "X_train.shape,y_train.value_counts(),y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4558d820-39bf-478a-8e54-6f0a81f93ec8",
   "metadata": {},
   "source": [
    "#### 1. Random Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "bd206417-b76d-4d45-8d43-a3d8bb07dfd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "undersamp = RandomUnderSampler(sampling_strategy=0.08, random_state=seed) # Voy a buscar una proporción de aprox 60%-40% \n",
    "X_train_under, y_train_under = undersamp.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "4f6728dd-8a52-41f4-8674-4a9da6884549",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((72954, 29),\n",
       " fraud_bool\n",
       " 0    67550\n",
       " 1     5404\n",
       " Name: count, dtype: int64,\n",
       " fraud_bool\n",
       " 0    0.925926\n",
       " 1    0.074074\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_under.shape,y_train_under.value_counts(),y_train_under.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "7662016b-49dd-4b87-9b68-8d315a0c561f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8419244897959184"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - X_train_under.shape[0] / X_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6053bc-0d45-4832-a16b-fc7172705a38",
   "metadata": {},
   "source": [
    "Logramos el cometido, el dataset está balanceado, pero solo nos quedamos con 27k datos, es decir que perdimos el 94% de nuestro dataset, \n",
    "dato que es al menos recalcable. Habrá que ver como funcionan los modelos con una reducción tan grande del dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a0a8ca-b119-4639-8de3-dc624e4e5b8c",
   "metadata": {},
   "source": [
    "#### 2. SMOTE OverSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "c24333fc-0302-4a6c-b7d3-6efda57c89e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "oversamp = SMOTE(sampling_strategy=0.25, random_state=seed)\n",
    "X_train_over, y_train_over = oversamp.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "214cb8ed-bd51-481b-b4a3-21acb5f1382c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((605745, 29),\n",
       " fraud_bool\n",
       " 0    484596\n",
       " 1    121149\n",
       " Name: count, dtype: int64,\n",
       " fraud_bool\n",
       " 0    0.8\n",
       " 1    0.2\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_over.shape,y_train_over.value_counts(),y_train_over.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "1d33051e-df02-4d8e-838f-2aaef3e059e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115745"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_over.value_counts()[1] - y_train.value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "bb7d3f9e-7047-4125-90a8-5ea272bc984c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2362142857142857"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_train_over.value_counts()[1] - y_train.value_counts()[1]) / y_train.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d410f90b-1342-4975-8938-c0fcc7b1636d",
   "metadata": {},
   "source": [
    "Con este método generamos 115k nuevos registros, es decir que agrandamos nuestro dataset de manera sintética casi un 24%, lo cual parece bastante,\n",
    "pero habrá que comprobarlo con los resultados del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c856ab3f-30c4-4773-85e9-cf80d686205d",
   "metadata": {},
   "source": [
    "#### 3. Mix con Pipeline (SMOTE OverSampling + UnderSampling):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "49778472-e63e-448d-9210-b72c011dfc08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "over = SMOTE(sampling_strategy=0.2, random_state=seed)\n",
    "under = RandomUnderSampler(sampling_strategy=0.25, random_state=seed) # Voy a buscar una proporción de aprox 60%-40%\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "X_train_mix, y_train_mix = pipeline.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "cc92b167-6f19-479b-a46d-f4649bbd359a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((484595, 29),\n",
       " fraud_bool\n",
       " 0    387676\n",
       " 1     96919\n",
       " Name: count, dtype: int64,\n",
       " fraud_bool\n",
       " 0    0.8\n",
       " 1    0.2\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mix.shape,y_train_mix.value_counts(),y_train_mix.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e977f4-81e0-4bf8-8234-750dc20a3467",
   "metadata": {
    "tags": []
   },
   "source": [
    "Vemos que de esta manera reducimos a poco más de la mitad los datos originales de train y la cantidad de datos a generar sintéticamente\n",
    "\n",
    "El tamaño del dataset no es minúsculo ni se expandió de manera tan abrupta, sino que casi que se mantuvo en su tamaño gracias al mix aplicado.\n",
    "\n",
    "Por supuesto que nunca vamos a llegar a una solución perfecta, pero esta pareciese ser la más razonable por el momento, aunque sin haberla medido. La hora de la verdad llegará cuando comencemos a probar los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00381f3a-9341-45a7-a54b-706423323ba3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>name_email_similarity</th>\n",
       "      <th>prev_address_months_count</th>\n",
       "      <th>current_address_months_count</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>days_since_request</th>\n",
       "      <th>intended_balcon_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>zip_count_4w</th>\n",
       "      <th>velocity_4w</th>\n",
       "      <th>bank_branch_count_8w</th>\n",
       "      <th>date_of_birth_distinct_emails_4w</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>credit_risk_score</th>\n",
       "      <th>email_is_free</th>\n",
       "      <th>housing_status</th>\n",
       "      <th>phone_home_valid</th>\n",
       "      <th>has_other_cards</th>\n",
       "      <th>proposed_credit_limit</th>\n",
       "      <th>foreign_request</th>\n",
       "      <th>session_length_in_minutes</th>\n",
       "      <th>device_os_other</th>\n",
       "      <th>device_os_linux</th>\n",
       "      <th>device_os_windows</th>\n",
       "      <th>device_os_macintosh</th>\n",
       "      <th>device_os_x11</th>\n",
       "      <th>keep_alive_session</th>\n",
       "      <th>device_distinct_emails_8w</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>339345</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.129004</td>\n",
       "      <td>56</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.016274</td>\n",
       "      <td>-0.760933</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2034</td>\n",
       "      <td>4847.050264</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.150540</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453683</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.231047</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>-1.319822</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1076</td>\n",
       "      <td>4801.842797</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.680771</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198425</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.550407</td>\n",
       "      <td>-1</td>\n",
       "      <td>324</td>\n",
       "      <td>50</td>\n",
       "      <td>0.028341</td>\n",
       "      <td>-0.604352</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1228</td>\n",
       "      <td>5519.625841</td>\n",
       "      <td>174</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.389204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165400</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.682156</td>\n",
       "      <td>-1</td>\n",
       "      <td>252</td>\n",
       "      <td>40</td>\n",
       "      <td>0.019537</td>\n",
       "      <td>-0.983700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1239</td>\n",
       "      <td>4377.519574</td>\n",
       "      <td>2119</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.341758</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72103</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.278175</td>\n",
       "      <td>98</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>0.517795</td>\n",
       "      <td>-0.709431</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1049</td>\n",
       "      <td>4312.921908</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.257548</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        income  name_email_similarity  prev_address_months_count  \\\n",
       "339345     0.8               0.129004                         56   \n",
       "453683     0.1               0.231047                         31   \n",
       "198425     0.7               0.550407                         -1   \n",
       "165400     0.4               0.682156                         -1   \n",
       "72103      0.9               0.278175                         98   \n",
       "\n",
       "        current_address_months_count  customer_age  days_since_request  \\\n",
       "339345                            10            30            0.016274   \n",
       "453683                             3            20            0.007882   \n",
       "198425                           324            50            0.028341   \n",
       "165400                           252            40            0.019537   \n",
       "72103                             20            40            0.517795   \n",
       "\n",
       "        intended_balcon_amount  payment_type  zip_count_4w  velocity_4w  \\\n",
       "339345               -0.760933           1.0          2034  4847.050264   \n",
       "453683               -1.319822           1.0          1076  4801.842797   \n",
       "198425               -0.604352           3.0          1228  5519.625841   \n",
       "165400               -0.983700           1.0          1239  4377.519574   \n",
       "72103                -0.709431           1.0          1049  4312.921908   \n",
       "\n",
       "        bank_branch_count_8w  date_of_birth_distinct_emails_4w  \\\n",
       "339345                    10                                10   \n",
       "453683                    12                                11   \n",
       "198425                   174                                 2   \n",
       "165400                  2119                                 2   \n",
       "72103                     35                                11   \n",
       "\n",
       "        employment_status  credit_risk_score  email_is_free  housing_status  \\\n",
       "339345                0.0                109              1             2.0   \n",
       "453683                0.0                 96              1             2.0   \n",
       "198425                1.0                218              0             0.0   \n",
       "165400                0.0                114              0             4.0   \n",
       "72103                 0.0                 53              0             0.0   \n",
       "\n",
       "        phone_home_valid  has_other_cards  proposed_credit_limit  \\\n",
       "339345                 0                1                  200.0   \n",
       "453683                 0                0                  500.0   \n",
       "198425                 0                0                 1500.0   \n",
       "165400                 1                0                  200.0   \n",
       "72103                  0                0                  500.0   \n",
       "\n",
       "        foreign_request  session_length_in_minutes  device_os_other  \\\n",
       "339345                0                   5.150540                0   \n",
       "453683                0                  15.680771                0   \n",
       "198425                0                   8.389204                0   \n",
       "165400                0                   3.341758                0   \n",
       "72103                 0                   3.257548                0   \n",
       "\n",
       "        device_os_linux  device_os_windows  device_os_macintosh  \\\n",
       "339345                1                  0                    0   \n",
       "453683                0                  0                    1   \n",
       "198425                0                  1                    0   \n",
       "165400                0                  0                    1   \n",
       "72103                 0                  0                    1   \n",
       "\n",
       "        device_os_x11  keep_alive_session  device_distinct_emails_8w  month  \n",
       "339345              0                   1                          1      3  \n",
       "453683              0                   1                          1      4  \n",
       "198425              0                   0                          1      2  \n",
       "165400              0                   1                          1      5  \n",
       "72103               0                   0                          1      5  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_mix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b3e4421-b97c-40d8-b71d-eaad81db4d68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# restauro el index:\n",
    "X_train_pipe_samp = X_train_pipe_samp.reset_index(drop=True)\n",
    "y_train_pipe_samp = y_train_pipe_samp.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a2c457-2d23-4851-b4ec-f53baec582db",
   "metadata": {},
   "source": [
    "## Añadido de PCA como prueba para mejora del modelo\n",
    "\n",
    "Además de los tratamientos realizados, generaré otro dataframe igual a X_train pero con las dos variables de PCA con el fin de, como se comentó en el notebook anterior, probar si mejoran el modelo o si por el contrario solo agregan ruido.\n",
    "\n",
    "Para ello importaré el modelo ya entrenado en el notebook anterior. Deberé aplicarlo primero sobre el Dataset con todas las variables y luego recortarlo (al haberse usado la misma semilla son exactamente iguales el completo y el recortado con la única diferencia de que uno tiene más variables que el otro):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9928010-45a6-4b05-a422-08527a84b94c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca = load('../models/pca_2components.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1f33ed99-dd51-402b-b299-844653b73c19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>name_email_similarity</th>\n",
       "      <th>prev_address_months_count</th>\n",
       "      <th>current_address_months_count</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>days_since_request</th>\n",
       "      <th>intended_balcon_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>zip_count_4w</th>\n",
       "      <th>velocity_4w</th>\n",
       "      <th>bank_branch_count_8w</th>\n",
       "      <th>date_of_birth_distinct_emails_4w</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>credit_risk_score</th>\n",
       "      <th>email_is_free</th>\n",
       "      <th>housing_status</th>\n",
       "      <th>phone_home_valid</th>\n",
       "      <th>has_other_cards</th>\n",
       "      <th>proposed_credit_limit</th>\n",
       "      <th>foreign_request</th>\n",
       "      <th>session_length_in_minutes</th>\n",
       "      <th>device_os_other</th>\n",
       "      <th>device_os_linux</th>\n",
       "      <th>device_os_windows</th>\n",
       "      <th>device_os_macintosh</th>\n",
       "      <th>device_os_x11</th>\n",
       "      <th>keep_alive_session</th>\n",
       "      <th>device_distinct_emails_8w</th>\n",
       "      <th>month</th>\n",
       "      <th>PCA1</th>\n",
       "      <th>PCA2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>599278</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.164202</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>0.014626</td>\n",
       "      <td>-1.047699</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1043</td>\n",
       "      <td>5997.273703</td>\n",
       "      <td>2154</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.839120</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6563.105547</td>\n",
       "      <td>3457.992940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499849</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.848983</td>\n",
       "      <td>-1</td>\n",
       "      <td>109</td>\n",
       "      <td>40</td>\n",
       "      <td>0.006597</td>\n",
       "      <td>-1.566874</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2964</td>\n",
       "      <td>4310.932705</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.010277</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5628.070298</td>\n",
       "      <td>2650.632267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345337</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.867902</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>0.005707</td>\n",
       "      <td>-1.613666</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1722</td>\n",
       "      <td>4635.000046</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.878469</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6832.737467</td>\n",
       "      <td>3278.452468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571314</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.477383</td>\n",
       "      <td>-1</td>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>0.002358</td>\n",
       "      <td>-1.509390</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1351</td>\n",
       "      <td>5293.455388</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.062248</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9203.977628</td>\n",
       "      <td>4184.075173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379586</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.349767</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>0.018052</td>\n",
       "      <td>-0.969820</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3059</td>\n",
       "      <td>5922.503266</td>\n",
       "      <td>36</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.505027</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7198.967957</td>\n",
       "      <td>3899.272516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        income  name_email_similarity  prev_address_months_count  \\\n",
       "599278     0.3               0.164202                         12   \n",
       "499849     0.9               0.848983                         -1   \n",
       "345337     0.1               0.867902                         26   \n",
       "571314     0.1               0.477383                         -1   \n",
       "379586     0.4               0.349767                         11   \n",
       "\n",
       "        current_address_months_count  customer_age  days_since_request  \\\n",
       "599278                            20            30            0.014626   \n",
       "499849                           109            40            0.006597   \n",
       "345337                            17            20            0.005707   \n",
       "571314                            60            40            0.002358   \n",
       "379586                             9            30            0.018052   \n",
       "\n",
       "        intended_balcon_amount  payment_type  zip_count_4w  velocity_4w  \\\n",
       "599278               -1.047699           1.0          1043  5997.273703   \n",
       "499849               -1.566874           2.0          2964  4310.932705   \n",
       "345337               -1.613666           1.0          1722  4635.000046   \n",
       "571314               -1.509390           2.0          1351  5293.455388   \n",
       "379586               -0.969820           3.0          3059  5922.503266   \n",
       "\n",
       "        bank_branch_count_8w  date_of_birth_distinct_emails_4w  \\\n",
       "599278                  2154                                12   \n",
       "499849                     0                                10   \n",
       "345337                     2                                18   \n",
       "571314                     0                                 8   \n",
       "379586                    36                                16   \n",
       "\n",
       "        employment_status  credit_risk_score  email_is_free  housing_status  \\\n",
       "599278                1.0                149              1             2.0   \n",
       "499849                0.0                152              0             1.0   \n",
       "345337                0.0                163              0             1.0   \n",
       "571314                0.0                 76              1             1.0   \n",
       "379586                0.0                185              1             2.0   \n",
       "\n",
       "        phone_home_valid  has_other_cards  proposed_credit_limit  \\\n",
       "599278                 0                0                  500.0   \n",
       "499849                 1                1                  200.0   \n",
       "345337                 1                0                  510.0   \n",
       "571314                 0                0                  200.0   \n",
       "379586                 0                0                 1500.0   \n",
       "\n",
       "        foreign_request  session_length_in_minutes  device_os_other  \\\n",
       "599278                0                   4.839120                0   \n",
       "499849                0                  11.010277                0   \n",
       "345337                0                   4.878469                1   \n",
       "571314                0                  26.062248                1   \n",
       "379586                0                   6.505027                1   \n",
       "\n",
       "        device_os_linux  device_os_windows  device_os_macintosh  \\\n",
       "599278                1                  0                    0   \n",
       "499849                0                  0                    1   \n",
       "345337                0                  0                    0   \n",
       "571314                0                  0                    0   \n",
       "379586                0                  0                    0   \n",
       "\n",
       "        device_os_x11  keep_alive_session  device_distinct_emails_8w  month  \\\n",
       "599278              0                   0                          1      3   \n",
       "499849              0                   1                          1      5   \n",
       "345337              0                   0                          1      3   \n",
       "571314              0                   0                          1      1   \n",
       "379586              0                   0                          1      2   \n",
       "\n",
       "               PCA1         PCA2  \n",
       "599278  6563.105547  3457.992940  \n",
       "499849  5628.070298  2650.632267  \n",
       "345337  6832.737467  3278.452468  \n",
       "571314  9203.977628  4184.075173  \n",
       "379586  7198.967957  3899.272516  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca = X_train.copy()\n",
    "X_val_pca = X_val.copy()\n",
    "X_train_pca['PCA1'], X_train_pca['PCA2'] = pca.transform(X_train_complete)[:,0], pca.transform(X_train_complete)[:,1]\n",
    "X_val_pca['PCA1'], X_val_pca['PCA2'] = pca.transform(X_val_complete)[:,0], pca.transform(X_val_complete)[:,1]\n",
    "X_train_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c51eab-b547-48ff-964c-1d05fc1850a8",
   "metadata": {},
   "source": [
    "## Resumen del tratamiento previo al modelado\n",
    "\n",
    "Una vez que he importado todos los datasets, generado sets de validación para comparar los modelos y agregar procesos de oversampling y undersampling, voy a proceder a la parte del modelado.\n",
    "\n",
    "El proceso de comentará a continuación en el siguiente apartado, pero antes de continuar voy a listar los datasets generados con los que voy a trabajar:\n",
    "\n",
    "1. Set sin recortes\n",
    "2. Set procesado con variables seleccionadas (5 menos que el original importado gracias al Feature Selection)\n",
    "3. Set escalado\n",
    "4. Set con variables PCA\n",
    "5. Set con Undersampling\n",
    "6. Set con Oversampling\n",
    "7. Set con mix Over y Under sampling.\n",
    "\n",
    "Aunque parecen muchos, son bastante similares entre si y la idea es realizar una validación numérica de con cual de ellos se obtendrían a priori mejores resultados, para no basarnos simplemente en intuición a la hora de buscar la optimización del uso de los datos disponibles en el modelo que elijamos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d9049d-8145-483c-a41d-32ba4c3ece06",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Modelado\n",
    "\n",
    "En este apartado de trataran los distintos modelos elegidos con los datasets disponibles. La idea es llegar al final del notebook con la elección tanto del modelo a utilizar, del dataset que mejor se adapte al mismo y de los hiperparámetros que optimizen los resultados buscados. Para lograrlo realizaré 3 pasos:\n",
    "\n",
    "1. Comparativa de modelos: Mediante un pipeline se probarán todos los modelos sin ajustar hiperparámetros, solo con sus valores por defecto, para ver cual es el que mejores resultados base proporciona.\n",
    "\n",
    "2. Comparativa de datasets: Con el modelo elegido se procederá a medir cual es el set de datos que mejores métricas obtiene.\n",
    "\n",
    "3. Búsqueda de hiperparámetros: Finalmente se realizará una búsqueda de los hiperparámetros que optimizen al modelo elegido en el dataset elegido mediante una Validación Cruzada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b2de22-2c2b-4471-97f5-486b658776e9",
   "metadata": {},
   "source": [
    "## Modelo Base:\n",
    "\n",
    "En primer lugar voy a realizar un modelo sin machine learning, en donde simplemente se asignará el valor de la clase mayoritaria a todos los resultados. En este caso, consideraremos que ninguna aplicación será fraudulenta. Esto es lo que haríamos si no pudiesemos aplicar ningún modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d9ba3c0-3295-41db-9d70-2fb5e7a146af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def y_pred_base_model(y_train, X_val):\n",
    "    value_max = y_train.value_counts(normalize=True).argmax()\n",
    "    size = X_val.index.value_counts().size\n",
    "    y_pred_base = np.random.choice([value_max, abs(1-value_max)], size=size, p=[abs(1-value_max),value_max])\n",
    "                  # preparé la función para dar valores random en otros casos, pero en este caso los valores serán una probabilidad fija.\n",
    "    return y_pred_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7203565-5b57-4d38-9144-a3b6862b390a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_base = y_pred_base_model(y_train,X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4640115-aef0-458e-9b55-0aa84309c79c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, ..., 0, 0, 0], dtype=int64), (210000,))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_base, y_pred_base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "88bd6266-5e17-49f4-828a-d3fd528c5639",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9889714285714286, 0.0, 0.0, 0.0, 0.5)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val,y_pred_base), f1_score(y_val,y_pred_base), precision_score(y_val,y_pred_base), recall_score(y_val,y_pred_base), balanced_accuracy_score(y_val,y_pred_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dbab31fa-8d91-491d-a371-1634d2467091",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[207684,      0],\n",
       "       [  2316,      0]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_val,y_pred_base)\n",
    "cf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59d1670d-0764-4c5f-948c-cb3ed79d3d85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98897143, 0.        ],\n",
       "       [0.01102857, 0.        ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_matrix_perc = cf_matrix/np.sum(cf_matrix)\n",
    "cf_matrix_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6b4691f9-042b-412d-9503-d8a7c350d905",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "heatmap = sns.heatmap(cf_matrix_perc, annot=True, fmt='.2%', cmap='Blues', linewidth=2)\n",
    "#plt.xlabel('Predictions', fontdict={'fontname':'Montserrat'})\n",
    "#plt.ylabel('Reality', fontdict={'fontname':'Montserrat'})\n",
    "plt.title('Confusion Matrix - Base Model', fontdict={'fontname':'Montserrat', 'fontsize':18})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4c9729-ef94-4f4b-a363-3760addc909c",
   "metadata": {},
   "source": [
    "Una vez contamos con el modelo base, procedemos a realizar la comparación de modelos con Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88a3876-bb6d-4f3f-9899-1f8c622b82a4",
   "metadata": {},
   "source": [
    "***\n",
    "# 1. Comparación de Modelos\n",
    "\n",
    "A continuación ejecutaré un pipeline con algunos de los modelos de clasificación \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43976e19-2a56-47a3-8e4d-280afa392404",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Antes de realizar el pipeline, voy a ejecutar la regresión logística, que a diferencia de los demás, necesita utilizar el dataset escalado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c876474c-6279-4ae0-a060-35658f503b38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy = 0.9889619047619047\n",
      "precision = 0.4444444444444444\n",
      "recall = 0.0034542314335060447\n",
      "f1_score = 0.006855184233076264\n",
      "confusion matrix:\n",
      "[[207674     10]\n",
      " [  2308      8]]\n",
      "\n",
      "CPU times: total: 2.94 s\n",
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(C=1)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "accuracy = accuracy_score(y_val,lr.predict(X_val_scaled))\n",
    "balanced_acc = balanced_accuracy_score(y_val,lr.predict(X_val_scaled))\n",
    "f1 = f1_score(y_val,lr.predict(X_val_scaled)) # (y_true, y_pred)\n",
    "c_matrix = confusion_matrix(y_val,lr.predict(X_val_scaled))\n",
    "precision = precision_score(y_val,lr.predict(X_val_scaled))\n",
    "recall = recall_score(y_val,lr.predict(X_val_scaled))\n",
    "print(f\"\"\"\n",
    "accuracy = {accuracy}\n",
    "balanced accuracy = {balanced_acc}\n",
    "precision = {precision}\n",
    "recall = {recall}\n",
    "f1_score = {f1}\n",
    "confusion matrix:\n",
    "{c_matrix}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2db4ec-c7d2-4af0-8f12-a7f1d25f2128",
   "metadata": {},
   "source": [
    "Ahora si procedo a probar el resto de los modelos en un pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "97c155a4-6896-4e38-8b98-b7ee2ac2fc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyClassifier()\n",
      "model score: 0.989\n",
      "\n",
      "    accuracy = 0.9889714285714286\n",
      "    precision = 0.0\n",
      "    recall = 0.0\n",
      "    f1_score = 0.0\n",
      "    confusion matrix:\n",
      "    [[207684      0]\n",
      " [  2316      0]]\n",
      "    \n",
      "GaussianNB()\n",
      "model score: 0.928\n",
      "\n",
      "    accuracy = 0.9282714285714285\n",
      "    precision = 0.0607209318354125\n",
      "    recall = 0.3803972366148532\n",
      "    f1_score = 0.10472511144130758\n",
      "    confusion matrix:\n",
      "    [[194056  13628]\n",
      " [  1435    881]]\n",
      "    \n",
      "DecisionTreeClassifier()\n",
      "model score: 0.977\n",
      "\n",
      "    accuracy = 0.9772619047619048\n",
      "    precision = 0.07353451266042317\n",
      "    recall = 0.09153713298791019\n",
      "    f1_score = 0.08155414502788998\n",
      "    confusion matrix:\n",
      "    [[205013   2671]\n",
      " [  2104    212]]\n",
      "    \n",
      "RandomForestClassifier(max_depth=10, n_estimators=120)\n",
      "model score: 0.989\n",
      "\n",
      "    accuracy = 0.9889761904761905\n",
      "    precision = 1.0\n",
      "    recall = 0.0004317789291882556\n",
      "    f1_score = 0.0008631851532153646\n",
      "    confusion matrix:\n",
      "    [[207684      0]\n",
      " [  2315      1]]\n",
      "    \n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=10, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=120, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)\n",
      "model score: 0.989\n",
      "\n",
      "    accuracy = 0.9887619047619047\n",
      "    precision = 0.3674698795180723\n",
      "    recall = 0.026338514680483593\n",
      "    f1_score = 0.04915390813859791\n",
      "    confusion matrix:\n",
      "    [[207579    105]\n",
      " [  2255     61]]\n",
      "    \n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 5404, number of negative: 484596\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2672\n",
      "[LightGBM] [Info] Number of data points in the train set: 490000, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.011029 -> initscore=-4.496176\n",
      "[LightGBM] [Info] Start training from score -4.496176\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "LGBMClassifier(max_depth=10, n_estimators=120)\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "model score: 0.989\n",
      "\n",
      "    accuracy = 0.9886285714285714\n",
      "    precision = 0.38\n",
      "    recall = 0.04922279792746114\n",
      "    f1_score = 0.08715596330275228\n",
      "    confusion matrix:\n",
      "    [[207498    186]\n",
      " [  2202    114]]\n",
      "    \n",
      "CPU times: total: 11min 39s\n",
      "Wall time: 6min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "classifiers = [\n",
    "    DummyClassifier()\n",
    "    ,GaussianNB()\n",
    "    ,DecisionTreeClassifier()\n",
    "    #,sm.glm() # https://medium.com/@sarka.pribylova/generalized-linear-model-f607ac7f0ef5\n",
    "    ,RandomForestClassifier(n_estimators=120, max_depth=10) # determino un número de árboles y de profundidad para que no haga overfitting y para que sean comparables los 3 modelos\n",
    "    ,XGBClassifier(n_estimators=120, max_depth=10)\n",
    "    ,LGBMClassifier(n_estimators=120, max_depth=10)\n",
    "    ]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    pipe = Pipeline(steps=[('classifier', classifier)])\n",
    "    pipe.fit(X_train, y_train)   \n",
    "    accuracy = accuracy_score(y_val,pipe.predict(X_val))\n",
    "    f1 = f1_score(y_val,pipe.predict(X_val)) # (y_true, y_pred)\n",
    "    c_matrix = confusion_matrix(y_val,pipe.predict(X_val))\n",
    "    precision = precision_score(y_val,pipe.predict(X_val))\n",
    "    recall = recall_score(y_val,pipe.predict(X_val))\n",
    "    print(classifier)\n",
    "    print(\"model score: %.3f\" % pipe.score(X_val, y_val))\n",
    "    print(f\"\"\"\n",
    "    accuracy = {accuracy}\n",
    "    precision = {precision}\n",
    "    recall = {recall}\n",
    "    f1_score = {f1}\n",
    "    confusion matrix:\n",
    "    {c_matrix}\n",
    "    \"\"\")\n",
    "\n",
    "# Voy a hacer este pipe para elegir modelo, dsps un for con modelos elegidos tmb sin hiperparams entre los 3 datasets (revisar seleccion de variables) para ver cual es el que\n",
    "# da mejor, y recién ahí, con el modelo y el dataset elegido voy a ejecutar, buscar hiperparámetros... Lo hago con el GRID o RANDOM con la CV (viene en la función)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f922d14f-0d8f-4999-b30d-37189fc455e0",
   "metadata": {},
   "source": [
    "# Comentar esto!\n",
    "\n",
    "En este caso el mejor modelo ha sido el LightGMB, por lo que será el modelo con el que trabajaré.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23412e8f-30aa-4063-a22b-a63b7598e67f",
   "metadata": {},
   "source": [
    "***\n",
    "# 2. Comparación de datasets\n",
    "\n",
    "Con el modelo elegido, en este caso el LightGBM voy a comprobar que set de datos obtiene mejores métricas.\n",
    "\n",
    "Como ya conozco las del dataset base, voy a probar con las demás variantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "07dbb42f-a9d8-477a-ba19-9fc5c4e12414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Info] Number of positive: 5404, number of negative: 484596\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3218\n",
      "[LightGBM] [Info] Number of data points in the train set: 490000, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.011029 -> initscore=-4.496176\n",
      "[LightGBM] [Info] Start training from score -4.496176\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "\u001b[1mSet completo\u001b[0m\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "model score: 0.989\n",
      "\n",
      "    accuracy = 0.9885285714285714\n",
      "    precision = 0.3523809523809524\n",
      "    recall = 0.04792746113989637\n",
      "    \u001b[1mf1_score = 0.08437856328392244\u001b[0m\n",
      "    confusion matrix:\n",
      "    [[207480    204]\n",
      " [  2205    111]]\n",
      "    \n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Info] Number of positive: 5404, number of negative: 484596\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3182\n",
      "[LightGBM] [Info] Number of data points in the train set: 490000, number of used features: 31\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.011029 -> initscore=-4.496176\n",
      "[LightGBM] [Info] Start training from score -4.496176\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "\u001b[1mSet con PCA\u001b[0m\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "model score: 0.989\n",
      "\n",
      "    accuracy = 0.9885047619047619\n",
      "    precision = 0.33774834437086093\n",
      "    recall = 0.04404145077720207\n",
      "    \u001b[1mf1_score = 0.07792207792207792\u001b[0m\n",
      "    confusion matrix:\n",
      "    [[207484    200]\n",
      " [  2214    102]]\n",
      "    \n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Info] Number of positive: 5404, number of negative: 67550\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003713 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2671\n",
      "[LightGBM] [Info] Number of data points in the train set: 72954, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.074074 -> initscore=-2.525729\n",
      "[LightGBM] [Info] Start training from score -2.525729\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "\u001b[1mSet Undersampling\u001b[0m\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "model score: 0.979\n",
      "\n",
      "    accuracy = 0.9791714285714286\n",
      "    precision = 0.1928358208955224\n",
      "    recall = 0.27892918825561314\n",
      "    \u001b[1mf1_score = 0.22802682668549243\u001b[0m\n",
      "    confusion matrix:\n",
      "    [[204980   2704]\n",
      " [  1670    646]]\n",
      "    \n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Info] Number of positive: 121149, number of negative: 484596\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033918 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3968\n",
      "[LightGBM] [Info] Number of data points in the train set: 605745, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.200000 -> initscore=-1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "\u001b[1mSet Oversampling\u001b[0m\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "model score: 0.988\n",
      "\n",
      "    accuracy = 0.9884666666666667\n",
      "    precision = 0.36683417085427134\n",
      "    recall = 0.06303972366148532\n",
      "    \u001b[1mf1_score = 0.10759027266028003\u001b[0m\n",
      "    confusion matrix:\n",
      "    [[207432    252]\n",
      " [  2170    146]]\n",
      "    \n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Info] Number of positive: 96919, number of negative: 387676\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043092 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3967\n",
      "[LightGBM] [Info] Number of data points in the train set: 484595, number of used features: 29\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.200000 -> initscore=-1.386294\n",
      "[LightGBM] [Info] Start training from score -1.386294\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "\u001b[1mSet Mix Over + Under sampling\u001b[0m\n",
      "[LightGBM] [Warning] Unknown parameter: max_depht\n",
      "model score: 0.988\n",
      "\n",
      "    accuracy = 0.9882761904761905\n",
      "    precision = 0.3534136546184739\n",
      "    recall = 0.07599309153713299\n",
      "    \u001b[1mf1_score = 0.12508884150675195\u001b[0m\n",
      "    confusion matrix:\n",
      "    [[207362    322]\n",
      " [  2140    176]]\n",
      "    \n",
      "CPU times: total: 1min 34s\n",
      "Wall time: 34.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgbm = LGBMClassifier(n_estimators=120, max_depht=10)\n",
    "datasets_train = [[X_train_complete, y_train_complete]\\\n",
    "                 ,[X_train_pca, y_train]\\\n",
    "                 ,[X_train_under, y_train_under]\\\n",
    "                 ,[X_train_over, y_train_over]\\\n",
    "                 ,[X_train_mix, y_train_mix]\\\n",
    "                 ]\n",
    "\n",
    "datasets_validation = [[X_val_complete, y_val_complete]\\\n",
    "                      ,[X_val_pca, y_val]\\\n",
    "                      ,[X_val, y_val]\\\n",
    "                      ,[X_val, y_val]\\\n",
    "                      ,[X_val, y_val]\\\n",
    "                       ]\n",
    "\n",
    "names = ['Set completo','Set con PCA', 'Set Undersampling', 'Set Oversampling', 'Set Mix Over + Under sampling']\n",
    "\n",
    "for train, val, name in zip(datasets_train, datasets_validation, names):\n",
    "    lgbm.fit(train[0], train[1])   \n",
    "    accuracy = accuracy_score(val[1],lgbm.predict(val[0]))\n",
    "    f1 = f1_score(val[1],lgbm.predict(val[0])) # (y_true, y_pred)\n",
    "    c_matrix = confusion_matrix(val[1],lgbm.predict(val[0]))\n",
    "    precision = precision_score(val[1],lgbm.predict(val[0]))\n",
    "    recall = recall_score(val[1],lgbm.predict(val[0]))\n",
    "    print(f'\\033[1m{name}\\033[0m')\n",
    "    print(\"model score: %.3f\" % lgbm.score(val[0], val[1]))\n",
    "    print(f\"\"\"\n",
    "    accuracy = {accuracy}\n",
    "    precision = {precision}\n",
    "    recall = {recall}\n",
    "    \\033[1mf1_score = {f1}\\033[0m\n",
    "    confusion matrix:\n",
    "    {c_matrix}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96ad9aa-b89e-4adb-8f6e-ab90e30e640a",
   "metadata": {},
   "source": [
    "### Conclusión de la comparación\n",
    "\n",
    "Realizar esta comparativa resultó ser realmente interesante, ya que son varias las conclusiones que podemos sacar:\n",
    "\n",
    "1. En primer lugar y más importante, es que el mix de samplings parece haber sido exitoso, siendo seguramente el set de datos elegido. Esto debido a que es el que más fraudes detectó de manera correcta, obteniendo el mejor F1 (buen balance entre precision y recall) sin ceder mucho accuracy.\n",
    "2. Igualmente, se debe recalcar que también se podría elegir la opción del puro Oversampling si se le da mayor importancia a la precisión que al Recall, aunque a nivel general parece un poco peor.\n",
    "3. Es interesante también ver como haber recortado algunas variables no solo ha mantenido las métricas del modelo, sino que las ha mejorado. Esto lo podemos observar comparando las métricas del modelo con las variables recortadas (el primero que calculamos en la comparativa de modelos) y las del set completo, donde el primero mejora tanto en precision como en Recall al segundo, con el mismo accuracy y con una menor necesidad de procesamiento por el simple hecho de tener menos atributos.\n",
    "4. También se descarta por completo la idea de que las variables del PCA pudiesen mejorar el modelo, ya que como vemos, parecen simplemente haber incluído ruido innecesario, empeorando las métricas del mismo.\n",
    "5. Finalmente he de hacer mención al desempeño del dataset con undersampling. Lamentablemente pierde demasiado Accuracy, pero a cambio es sorprendente el recall tan alto que obtiene, siendo claramente el set que más capta fraudes, pero con el gran peligro de a su vez generar una gran cantidad de falsos positivos, lo que lo hace inviable...\n",
    "\n",
    "Una vez determinado tanto el modelo como el set a utilizar, procederé a llevar a cabo la búsqueda de hiperparámetros:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f073f36c-25e6-408e-8fa4-36bf60dd7b4a",
   "metadata": {},
   "source": [
    "# <font color='red'>Para hacer:</font>\n",
    "\n",
    "- <s>PCA o T-SNE graficando 2 componentes</s>\n",
    "- <s>TEST DE VAL EN EL 03, antes del oversampling!</s>\n",
    "- <s>Crear variable random y medir en el random forest de selección de variables! (hacer pd.concat con el train y el test!)</s>\n",
    "- <s>Logistic Regression</s>\n",
    "- GLM\n",
    "- Explicar selección de modelos y de datasets\n",
    "- Buscar hiperparámetros con Grid Search en XGBoos y LightGBM\n",
    "- BUSINESS CASE\n",
    "\n",
    "# ORDENAR:\n",
    "\n",
    "Antes que nada: Nuevo directorio con todo igual pero nuevo\n",
    "Nuevo orden de notebooks:\n",
    "1. 01_Introduction_EDA\n",
    "    - **Agregar Business Case**\n",
    "        - **Si mi idea es que el modelo se ejecute ante cada aplicación, el \"day_since_request\" Sería una variable inutilizable!!!** Ver esto!\n",
    "    - <s>**Revisar si cambiamos o no los -1 por -666**</s> --> Por ahora NO --> **Preguntar a Ana**\n",
    "2. 02_EDA_and_Split\n",
    "    - <s>Mantengo igual pero a esto le sumo la conclusión</s>\n",
    "    - <s>**Hacer confusion Matrix como quiere Diego**</s>\n",
    "    - **PASAR LA CONFUSION MÁTRIX A FUNCIÓN**\n",
    "    - <s>**Ver posibilidad de actualizar la Cramers-V Matrix - Recordar actualizar la escala de colores a Divergente!**</s> --> Hay q tocar la función si quiero eso\n",
    "3. 03_Feature_Processing\n",
    "    - Acá va todo lo nuevo:\n",
    "         1. <s>Feature Engineering (Encodings, Scaling y **PCA+kmeans**)</s>\n",
    "         2. <s>Feature Selection</s>\n",
    "             - <s>**Unificar Train y Test acá**</s>\n",
    "             - <s>Random Forest --> Meter y dsps eliminar variable random entre 1 y 1000. Recordar NO eliminar columns del OHE</s>\n",
    "             - <s>Lasso --> Eliminar una column del OHE</s>\n",
    "         3. **Nuevo diccionario de datos!**\n",
    "         4. <s>Exporto todos los DS listos</s>\n",
    "             - <s>Train y Test normales</s>\n",
    "             - <s>Exporto pickle de PCA</s>\n",
    "4. 04_Model_Selection\n",
    "    1. <s>Importo todo:</s>\n",
    "        - <s>Train y Test base</s>\n",
    "        - <s>Train y Test scaled</s>\n",
    "        - <s>**PCA (importando pickle)**</s>\n",
    "    2. <s>Train_Validation split\n",
    "        - Tanto escalado como normal</s>\n",
    "    3. <s>OverSampling y UnderSampling\n",
    "        - 3 posibilidades: Under, Over y Mix</s>\n",
    "    4. <s>Modelo Base --> Sobre el DS Base</s>\n",
    "    5. <s>**Regresión Logística --> Aplicar Scaled**</s>\n",
    "    6. <s>**Pipeline selección del modelo (f1, precision, accuracy, recall, roc_auc y confusion_matrix)**</s>\n",
    "    7. <s>**Pipeline selección dataset (mismas métricas)**\n",
    "        - Dataset original\n",
    "        - Dataset Recortado por featuring selection\n",
    "        - Dataset Recortado + PCA\n",
    "        - UnderSampling\n",
    "        - OverSampling\n",
    "        - MixSamplings</s>\n",
    "    8. **Explicación de la selección del modelo con métricas**\n",
    "5. 05_Model_Fit_and_Metrics\n",
    "     1. Búsqueda de hiperparámetros\n",
    "     2. Fit del modelo y predict\n",
    "     3. Métricas\n",
    "     4. Threshold + Confusion Matrix\n",
    "     5. ROC Curve, Gain Curve, Lift plot y Precision_REcall curve\n",
    "     6. CONCLUSIONES DE LA ELECCIÓN Y PREDICCIÓN\n",
    "6. 06_Explainability? Explicabilidad o interpretabilidad?\n",
    "    - SHAP plots\n",
    "    - SHAP clustering!\n",
    "7. 07_Review_Conclusions\n",
    "\n",
    "# HACER SMV! AL MENOS CON POCOS DATOS!\n",
    "\n",
    "## Revisar todo y ver que se puede pasar a FUNCIONES!\n",
    "- Confusion Matrix por ejemplo!\n",
    "\n",
    "LightGBM vs XGBoost: https://www.juanbarrios.com/light-gbm-vs-xgboost-cual-es-mejor-algoritmo/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e2855f-efb2-4136-afe1-7b9f28cf7627",
   "metadata": {},
   "source": [
    "## Búsqueda de hiperparámetros\n",
    "\n",
    "En la <a href='https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html'>documentación de LightGBM</a> se dan algunos consejos sobre el tunning de los hiperparámetros del modelo, los cuales por cierto pueden ser muchos más.\n",
    "\n",
    "Yo me he dedicado a comprobar entre los principales nombrados, siguiendo algunas indicaciones para determinar los valores elegidos, intentando que no permitan el overfitting ni underfitting.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7fb5080d-d917-421c-8dde-76ecf997300e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "683"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(2**10/1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "73182af9-1a1a-4029-9efa-acee993f3c90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 5404, number of negative: 67550\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2669\n",
      "[LightGBM] [Info] Number of data points in the train set: 72954, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.074074 -> initscore=-2.525729\n",
      "[LightGBM] [Info] Start training from score -2.525729\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "{'reg_lambda': 0.1, 'reg_alpha': 0.1, 'num_leaves': 300, 'n_estimators ': 400, 'min_data_in_leaf': 1600, 'max_depth': 10, 'learning_rate': 0.05}\n",
      "0.3434612012890702\n",
      "CPU times: total: 9.27 s\n",
      "Wall time: 46.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgbm = LGBMClassifier()\n",
    "param_grid = { \n",
    "    'max_depth' : [4,6,8,10]\n",
    "    ,'num_leaves' : [round(2**4/1.5),round(2**5/1.5),round(2**6/1.5),round(2**8/1.5),150, 300, round(2**10/1.5)]\n",
    "    ,'min_data_in_leaf' :[100,400,800,1200,1600]\n",
    "    ,'n_estimators ': [200,300,400,500,600,700]\n",
    "    ,'learning_rate': [0.001, 0.005, 0.01, 0.02, 0.05]\n",
    "    ,'reg_alpha': [0, 0.1, 0.5]\n",
    "    ,'reg_lambda': [0, 0.1, 0.5]\n",
    "    #,'scale_pos_weight': [(y_train.value_counts(normalize=True)[0]/y_train.value_counts(normalize=True)[1])] # nivel de desequilibrio del dataset.\n",
    "}\n",
    "\n",
    "CV = RandomizedSearchCV(lgbm, param_grid, cv=10, random_state=seed, n_jobs=2, scoring='f1')\n",
    "                  \n",
    "CV.fit(X_train_under, y_train_under)\n",
    "print(CV.best_params_)    \n",
    "print(CV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "77094e7e-f80b-4050-8cbf-f4e50057f9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Warning] Unknown parameter: 400\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Warning] num_iterations is set=100, n_estimators= will be ignored. Current value: num_iterations=100\n",
      "[LightGBM] [Info] Number of positive: 5404, number of negative: 67550\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2669\n",
      "[LightGBM] [Info] Number of data points in the train set: 72954, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.074074 -> initscore=-2.525729\n",
      "[LightGBM] [Info] Start training from score -2.525729\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "{'reg_lambda': 0.1, 'reg_alpha': 0.1, 'num_leaves': 300, 'n_estimators ': 400, 'min_data_in_leaf': 1600, 'max_depth': 10, 'learning_rate': 0.05}\n",
      "0.3434612012890702\n",
      "CPU times: total: 9.12 s\n",
      "Wall time: 41.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgbm = LGBMClassifier()\n",
    "param_grid = { \n",
    "    'max_depth' : [4,6,8,10]\n",
    "    ,'num_leaves' : [round(2**4/1.5),round(2**5/1.5),round(2**6/1.5),round(2**8/1.5),150, 300, round(2**10/1.5)]\n",
    "    ,'min_data_in_leaf' :[200,400,800,1200,1600]\n",
    "    ,'n_estimators ': [200,300,400,500,600,700]\n",
    "    ,'learning_rate': [0.001, 0.005, 0.01, 0.02, 0.05]\n",
    "    ,'reg_alpha': [0, 0.1, 0.5]\n",
    "    ,'reg_lambda': [0, 0.1, 0.5]\n",
    "    #,'scale_pos_weight': [(y_train.value_counts(normalize=True)[0]/y_train.value_counts(normalize=True)[1])] # nivel de desequilibrio del dataset.\n",
    "}\n",
    "\n",
    "scoring = ['f1', 'accuracy', 'balanced_accuracy', 'precision', 'recall','roc_auc']\n",
    "\n",
    "CV = RandomizedSearchCV(lgbm, param_grid, cv=10, random_state=seed, n_jobs=2, scoring=scoring, refit='f1')\n",
    "                  \n",
    "CV.fit(X_train_under, y_train_under)  \n",
    "print(CV.best_params_)    \n",
    "print(CV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "2e3846ee-7ebb-46a3-b8ca-6a15b0c1496f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-27 {color: black;}#sk-container-id-27 pre{padding: 0;}#sk-container-id-27 div.sk-toggleable {background-color: white;}#sk-container-id-27 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-27 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-27 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-27 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-27 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-27 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-27 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-27 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-27 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-27 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-27 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-27 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-27 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-27 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-27 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-27 div.sk-item {position: relative;z-index: 1;}#sk-container-id-27 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-27 div.sk-item::before, #sk-container-id-27 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-27 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-27 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-27 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-27 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-27 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-27 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-27 div.sk-label-container {text-align: center;}#sk-container-id-27 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-27 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-27\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.05, max_depth=10, min_data_in_leaf=1600,\n",
       "               n_estimators =400, num_leaves=300, reg_alpha=0.1,\n",
       "               reg_lambda=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" checked><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.05, max_depth=10, min_data_in_leaf=1600,\n",
       "               n_estimators =400, num_leaves=300, reg_alpha=0.1,\n",
       "               reg_lambda=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.05, max_depth=10, min_data_in_leaf=1600,\n",
       "               n_estimators =400, num_leaves=300, reg_alpha=0.1,\n",
       "               reg_lambda=0.1)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "299d00b9-810c-4668-a34d-8218fa2376fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reg_lambda': 0.1,\n",
       " 'reg_alpha': 0.1,\n",
       " 'num_leaves': 300,\n",
       " 'n_estimators ': 400,\n",
       " 'min_data_in_leaf': 1600,\n",
       " 'max_depth': 10,\n",
       " 'learning_rate': 0.05}"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "3a2a2e16-de71-4a93-a2fa-51fb2453403c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3434612012890702"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "4cf5bc40-69a0-4937-897c-b299ecc754e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_accuracy: \n",
      "[0.92651535 0.93129914 0.92943496 0.92592593 0.92592593 0.93520577\n",
      " 0.92595334 0.92592593 0.92592593 0.92592593]\n",
      "mean_test_f1: \n",
      "[0.01829905 0.17795589 0.12070906 0.         0.         0.3434612\n",
      " 0.00073869 0.         0.         0.        ]\n",
      "mean_test_precision: \n",
      "[0.89702381 0.7827808  0.785103   0.         0.         0.68887399\n",
      " 0.2        0.         0.         0.        ]\n",
      "mean_test_recall: \n",
      "[0.00925344 0.10065585 0.06549976 0.         0.         0.22908195\n",
      " 0.00037003 0.         0.         0.        ]\n",
      "mean_test_roc_auc: \n",
      "[0.86441808 0.88157915 0.87832258 0.83443698 0.85623505 0.89187331\n",
      " 0.85809834 0.84873576 0.83445059 0.83444714]\n"
     ]
    }
   ],
   "source": [
    "metrics = ['mean_test_accuracy','mean_test_f1','mean_test_precision','mean_test_recall','mean_test_roc_auc']\n",
    "for i in metrics:\n",
    "    print(f'{i}: \\n{CV.cv_results_[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "ecdd5129-5596-49da-95ee-9fc3ba127969",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV.cv_results_['rank_test_accuracy'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "dcde036e-b69e-43a1-8595-3314269426a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\n",
      "mean_test_accuracy: 0.92593\n",
      "mean_test_f1: 0.00000\n",
      "mean_test_precision: 0.00000\n",
      "mean_test_recall: 0.00000\n",
      "mean_test_roc_auc: 0.83445\n",
      "1:\n",
      "mean_test_accuracy: 0.92652\n",
      "mean_test_f1: 0.01830\n",
      "mean_test_precision: 0.89702\n",
      "mean_test_recall: 0.00925\n",
      "mean_test_roc_auc: 0.86442\n",
      "2:\n",
      "mean_test_accuracy: 0.93130\n",
      "mean_test_f1: 0.17796\n",
      "mean_test_precision: 0.78278\n",
      "mean_test_recall: 0.10066\n",
      "mean_test_roc_auc: 0.88158\n",
      "3:\n",
      "mean_test_accuracy: 0.92943\n",
      "mean_test_f1: 0.12071\n",
      "mean_test_precision: 0.78510\n",
      "mean_test_recall: 0.06550\n",
      "mean_test_roc_auc: 0.87832\n",
      "4:\n",
      "mean_test_accuracy: 0.92593\n",
      "mean_test_f1: 0.00000\n",
      "mean_test_precision: 0.00000\n",
      "mean_test_recall: 0.00000\n",
      "mean_test_roc_auc: 0.83444\n",
      "5:\n",
      "mean_test_accuracy: 0.92593\n",
      "mean_test_f1: 0.00000\n",
      "mean_test_precision: 0.00000\n",
      "mean_test_recall: 0.00000\n",
      "mean_test_roc_auc: 0.85624\n",
      "6:\n",
      "mean_test_accuracy: 0.93521\n",
      "mean_test_f1: 0.34346\n",
      "mean_test_precision: 0.68887\n",
      "mean_test_recall: 0.22908\n",
      "mean_test_roc_auc: 0.89187\n",
      "7:\n",
      "mean_test_accuracy: 0.92595\n",
      "mean_test_f1: 0.00074\n",
      "mean_test_precision: 0.20000\n",
      "mean_test_recall: 0.00037\n",
      "mean_test_roc_auc: 0.85810\n",
      "8:\n",
      "mean_test_accuracy: 0.92593\n",
      "mean_test_f1: 0.00000\n",
      "mean_test_precision: 0.00000\n",
      "mean_test_recall: 0.00000\n",
      "mean_test_roc_auc: 0.84874\n",
      "9:\n",
      "mean_test_accuracy: 0.92593\n",
      "mean_test_f1: 0.00000\n",
      "mean_test_precision: 0.00000\n",
      "mean_test_recall: 0.00000\n",
      "mean_test_roc_auc: 0.83445\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    print(f'{i}:')\n",
    "    for metric in metrics:\n",
    "        print(f'{metric}: {CV.cv_results_[metric][i-1]:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "5d94b619-9ed6-4585-9ff6-7f10fac48df1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92651535 0.93129914 0.92943496 0.92592593 0.92592593 0.93520577\n",
      " 0.92595334 0.92592593 0.92592593 0.92592593]\n",
      "[0.01829905 0.17795589 0.12070906 0.         0.         0.3434612\n",
      " 0.00073869 0.         0.         0.        ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.62912824, 0.78767419, 0.70000386, 0.72803752, 0.94044154,\n",
       "        0.84995182, 0.68417261, 0.59974551, 0.60457568, 0.61757441]),\n",
       " 'std_fit_time': array([0.03506546, 0.09061834, 0.11630456, 0.09110316, 0.07250444,\n",
       "        0.04660198, 0.03050029, 0.01695888, 0.01353278, 0.04783454]),\n",
       " 'mean_score_time': array([0.05086715, 0.06981254, 0.06939855, 0.06044402, 0.06758394,\n",
       "        0.08254673, 0.06449673, 0.06015441, 0.05791018, 0.05461152]),\n",
       " 'std_score_time': array([0.00307642, 0.02553012, 0.02036049, 0.00450221, 0.00291572,\n",
       "        0.00269815, 0.00333644, 0.00297727, 0.00394871, 0.00650734]),\n",
       " 'param_reg_lambda': masked_array(data=[0, 0, 0, 0, 0.1, 0.1, 0, 0.5, 0.5, 0.1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_reg_alpha': masked_array(data=[0.5, 0.1, 0, 0.1, 0.1, 0.1, 0.1, 0.1, 0.5, 0],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_num_leaves': masked_array(data=[171, 171, 300, 300, 683, 300, 21, 300, 43, 171],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators ': masked_array(data=[600, 300, 200, 600, 700, 400, 400, 700, 400, 500],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_data_in_leaf': masked_array(data=[400, 800, 1600, 1600, 400, 1600, 800, 800, 1600, 1600],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[6, 10, 8, 4, 6, 10, 6, 4, 4, 4],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_learning_rate': masked_array(data=[0.01, 0.02, 0.02, 0.005, 0.005, 0.05, 0.01, 0.01,\n",
       "                    0.005, 0.005],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'reg_lambda': 0,\n",
       "   'reg_alpha': 0.5,\n",
       "   'num_leaves': 171,\n",
       "   'n_estimators ': 600,\n",
       "   'min_data_in_leaf': 400,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.01},\n",
       "  {'reg_lambda': 0,\n",
       "   'reg_alpha': 0.1,\n",
       "   'num_leaves': 171,\n",
       "   'n_estimators ': 300,\n",
       "   'min_data_in_leaf': 800,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.02},\n",
       "  {'reg_lambda': 0,\n",
       "   'reg_alpha': 0,\n",
       "   'num_leaves': 300,\n",
       "   'n_estimators ': 200,\n",
       "   'min_data_in_leaf': 1600,\n",
       "   'max_depth': 8,\n",
       "   'learning_rate': 0.02},\n",
       "  {'reg_lambda': 0,\n",
       "   'reg_alpha': 0.1,\n",
       "   'num_leaves': 300,\n",
       "   'n_estimators ': 600,\n",
       "   'min_data_in_leaf': 1600,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.005},\n",
       "  {'reg_lambda': 0.1,\n",
       "   'reg_alpha': 0.1,\n",
       "   'num_leaves': 683,\n",
       "   'n_estimators ': 700,\n",
       "   'min_data_in_leaf': 400,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.005},\n",
       "  {'reg_lambda': 0.1,\n",
       "   'reg_alpha': 0.1,\n",
       "   'num_leaves': 300,\n",
       "   'n_estimators ': 400,\n",
       "   'min_data_in_leaf': 1600,\n",
       "   'max_depth': 10,\n",
       "   'learning_rate': 0.05},\n",
       "  {'reg_lambda': 0,\n",
       "   'reg_alpha': 0.1,\n",
       "   'num_leaves': 21,\n",
       "   'n_estimators ': 400,\n",
       "   'min_data_in_leaf': 800,\n",
       "   'max_depth': 6,\n",
       "   'learning_rate': 0.01},\n",
       "  {'reg_lambda': 0.5,\n",
       "   'reg_alpha': 0.1,\n",
       "   'num_leaves': 300,\n",
       "   'n_estimators ': 700,\n",
       "   'min_data_in_leaf': 800,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.01},\n",
       "  {'reg_lambda': 0.5,\n",
       "   'reg_alpha': 0.5,\n",
       "   'num_leaves': 43,\n",
       "   'n_estimators ': 400,\n",
       "   'min_data_in_leaf': 1600,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.005},\n",
       "  {'reg_lambda': 0.1,\n",
       "   'reg_alpha': 0,\n",
       "   'num_leaves': 171,\n",
       "   'n_estimators ': 500,\n",
       "   'min_data_in_leaf': 1600,\n",
       "   'max_depth': 4,\n",
       "   'learning_rate': 0.005}],\n",
       " 'split0_test_f1': array([0.01824818, 0.21621622, 0.14765101, 0.        , 0.        ,\n",
       "        0.37967914, 0.00369004, 0.        , 0.        , 0.        ]),\n",
       " 'split1_test_f1': array([0.01102941, 0.1900161 , 0.12182741, 0.        , 0.        ,\n",
       "        0.32647462, 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'split2_test_f1': array([0.0146789 , 0.2038835 , 0.14478114, 0.        , 0.        ,\n",
       "        0.35068493, 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'split3_test_f1': array([0.01831502, 0.18892508, 0.13536379, 0.        , 0.        ,\n",
       "        0.35245902, 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'split4_test_f1': array([0.02193784, 0.17190083, 0.10745234, 0.        , 0.        ,\n",
       "        0.33097595, 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'split5_test_f1': array([0.02193784, 0.15745394, 0.10416667, 0.        , 0.        ,\n",
       "        0.34357542, 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'split6_test_f1': array([0.02559415, 0.14642263, 0.1       , 0.        , 0.        ,\n",
       "        0.32248939, 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'split7_test_f1': array([0.01104972, 0.13874788, 0.10398614, 0.        , 0.        ,\n",
       "        0.32091691, 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'split8_test_f1': array([0.02554745, 0.18923328, 0.11643836, 0.        , 0.        ,\n",
       "        0.36842105, 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'split9_test_f1': array([0.01465201, 0.17675941, 0.12542373, 0.        , 0.        ,\n",
       "        0.33893557, 0.00369686, 0.        , 0.        , 0.        ]),\n",
       " 'mean_test_f1': array([0.01829905, 0.17795589, 0.12070906, 0.        , 0.        ,\n",
       "        0.3434612 , 0.00073869, 0.        , 0.        , 0.        ]),\n",
       " 'std_test_f1': array([0.00513857, 0.02349273, 0.01649159, 0.        , 0.        ,\n",
       "        0.01865706, 0.00147738, 0.        , 0.        , 0.        ]),\n",
       " 'rank_test_f1': array([4, 2, 3, 6, 6, 1, 5, 6, 6, 6]),\n",
       " 'split0_test_accuracy': array([0.92626096, 0.93242873, 0.93037281, 0.92584978, 0.92584978,\n",
       "        0.93640351, 0.92598684, 0.92584978, 0.92584978, 0.92584978]),\n",
       " 'split1_test_accuracy': array([0.92626096, 0.93105811, 0.92886513, 0.92584978, 0.92584978,\n",
       "        0.93270285, 0.92584978, 0.92584978, 0.92584978, 0.92584978]),\n",
       " 'split2_test_accuracy': array([0.92639803, 0.93256579, 0.93037281, 0.92584978, 0.92584978,\n",
       "        0.93503289, 0.92584978, 0.92584978, 0.92584978, 0.92584978]),\n",
       " 'split3_test_accuracy': array([0.92653509, 0.93174342, 0.92996162, 0.92584978, 0.92584978,\n",
       "        0.93503289, 0.92584978, 0.92584978, 0.92584978, 0.92584978]),\n",
       " 'split4_test_accuracy': array([0.9266621 , 0.93132282, 0.9294037 , 0.9259767 , 0.9259767 ,\n",
       "        0.93516107, 0.9259767 , 0.9259767 , 0.9259767 , 0.9259767 ]),\n",
       " 'split5_test_accuracy': array([0.9266621 , 0.93104866, 0.92926662, 0.9259767 , 0.9259767 ,\n",
       "        0.93557231, 0.9259767 , 0.9259767 , 0.9259767 , 0.9259767 ]),\n",
       " 'split6_test_accuracy': array([0.92693626, 0.92967786, 0.92844414, 0.9259767 , 0.9259767 ,\n",
       "        0.93433859, 0.9259767 , 0.9259767 , 0.9259767 , 0.9259767 ]),\n",
       " 'split7_test_accuracy': array([0.92638794, 0.93022618, 0.92912954, 0.9259767 , 0.9259767 ,\n",
       "        0.93502399, 0.9259767 , 0.9259767 , 0.9259767 , 0.9259767 ]),\n",
       " 'split8_test_accuracy': array([0.92679918, 0.93187114, 0.92926662, 0.9259767 , 0.9259767 ,\n",
       "        0.93749143, 0.9259767 , 0.9259767 , 0.9259767 , 0.9259767 ]),\n",
       " 'split9_test_accuracy': array([0.92625086, 0.93104866, 0.92926662, 0.9259767 , 0.9259767 ,\n",
       "        0.93529815, 0.92611378, 0.9259767 , 0.9259767 , 0.9259767 ]),\n",
       " 'mean_test_accuracy': array([0.92651535, 0.93129914, 0.92943496, 0.92592593, 0.92592593,\n",
       "        0.93520577, 0.92595334, 0.92592593, 0.92592593, 0.92592593]),\n",
       " 'std_test_accuracy': array([2.30338805e-04, 8.58420554e-04, 5.93480322e-04, 6.21757242e-05,\n",
       "        6.21757242e-05, 1.17953971e-03, 7.85897351e-05, 6.21757242e-05,\n",
       "        6.21757242e-05, 6.21757242e-05]),\n",
       " 'rank_test_accuracy': array([4, 2, 3, 6, 6, 1, 5, 6, 6, 6]),\n",
       " 'split0_test_balanced_accuracy': array([0.50447303, 0.5613662 , 0.53985122, 0.5       , 0.5       ,\n",
       "        0.6264272 , 0.50092421, 0.5       , 0.5       , 0.5       ]),\n",
       " 'split1_test_balanced_accuracy': array([0.50277264, 0.55297425, 0.53223545, 0.5       , 0.5       ,\n",
       "        0.60487419, 0.5       , 0.5       , 0.5       , 0.5       ]),\n",
       " 'split2_test_balanced_accuracy': array([0.50369686, 0.55718924, 0.53900103, 0.5       , 0.5       ,\n",
       "        0.61378427, 0.5       , 0.5       , 0.5       , 0.5       ]),\n",
       " 'split3_test_balanced_accuracy': array([0.50462107, 0.55249415, 0.53622838, 0.5       , 0.5       ,\n",
       "        0.61463447, 0.5       , 0.5       , 0.5       , 0.5       ]),\n",
       " 'split4_test_balanced_accuracy': array([0.50548154, 0.5471859 , 0.52825959, 0.5       , 0.5       ,\n",
       "        0.60463237, 0.5       , 0.5       , 0.5       , 0.5       ]),\n",
       " 'split5_test_balanced_accuracy': array([0.50548154, 0.54277833, 0.52733366, 0.5       , 0.5       ,\n",
       "        0.60996587, 0.5       , 0.5       , 0.5       , 0.5       ]),\n",
       " 'split6_test_balanced_accuracy': array([0.50648148, 0.53948241, 0.52603764, 0.5       , 0.5       ,\n",
       "        0.60163254, 0.5       , 0.5       , 0.5       , 0.5       ]),\n",
       " 'split7_test_balanced_accuracy': array([0.50277778, 0.53722277, 0.52725964, 0.5       , 0.5       ,\n",
       "        0.60029882, 0.5       , 0.5       , 0.5       , 0.5       ]),\n",
       " 'split8_test_balanced_accuracy': array([0.50640746, 0.55259342, 0.53074129, 0.5       , 0.5       ,\n",
       "        0.61952121, 0.5       , 0.5       , 0.5       , 0.5       ]),\n",
       " 'split9_test_balanced_accuracy': array([0.50355567, 0.54874167, 0.53329701, 0.5       , 0.5       ,\n",
       "        0.60811402, 0.50092593, 0.5       , 0.5       , 0.5       ]),\n",
       " 'mean_test_balanced_accuracy': array([0.50457491, 0.54920283, 0.53202449, 0.5       , 0.5       ,\n",
       "        0.61038849, 0.50018501, 0.5       , 0.5       , 0.5       ]),\n",
       " 'std_test_balanced_accuracy': array([0.00130144, 0.00729278, 0.00475013, 0.        , 0.        ,\n",
       "        0.00785854, 0.00037003, 0.        , 0.        , 0.        ]),\n",
       " 'rank_test_balanced_accuracy': array([4, 2, 3, 6, 6, 1, 5, 6, 6, 6]),\n",
       " 'split0_test_precision': array([0.71428571, 0.77272727, 0.8       , 0.        , 0.        ,\n",
       "        0.68599034, 1.        , 0.        , 0.        , 0.        ]),\n",
       " 'split1_test_precision': array([1.        , 0.7375    , 0.72      , 0.        , 0.        ,\n",
       "        0.63297872, 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'split2_test_precision': array([1.        , 0.81818182, 0.81132075, 0.        , 0.        ,\n",
       "        0.67724868, 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'split3_test_precision': array([1.        , 0.79452055, 0.8       , 0.        , 0.        ,\n",
       "        0.67539267, 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'split4_test_precision': array([0.85714286, 0.8       , 0.83783784, 0.        , 0.        ,\n",
       "        0.7005988 , 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'split5_test_precision': array([0.85714286, 0.8245614 , 0.83333333, 0.        , 0.        ,\n",
       "        0.69886364, 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'split6_test_precision': array([1.        , 0.72131148, 0.725     , 0.        , 0.        ,\n",
       "        0.68263473, 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'split7_test_precision': array([1.        , 0.80392157, 0.81081081, 0.        , 0.        ,\n",
       "        0.70886076, 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'split8_test_precision': array([0.875     , 0.79452055, 0.77272727, 0.        , 0.        ,\n",
       "        0.73076923, 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'split9_test_precision': array([0.66666667, 0.76056338, 0.74      , 0.        , 0.        ,\n",
       "        0.6954023 , 1.        , 0.        , 0.        , 0.        ]),\n",
       " 'mean_test_precision': array([0.89702381, 0.7827808 , 0.785103  , 0.        , 0.        ,\n",
       "        0.68887399, 0.2       , 0.        , 0.        , 0.        ]),\n",
       " 'std_test_precision': array([0.11964286, 0.03231322, 0.04115512, 0.        , 0.        ,\n",
       "        0.02433718, 0.4       , 0.        , 0.        , 0.        ]),\n",
       " 'rank_test_precision': array([1, 3, 2, 6, 6, 4, 5, 6, 6, 6]),\n",
       " 'split0_test_recall': array([0.00924214, 0.12569316, 0.08133087, 0.        , 0.        ,\n",
       "        0.26247689, 0.00184843, 0.        , 0.        , 0.        ]),\n",
       " 'split1_test_recall': array([0.00554529, 0.1090573 , 0.06654344, 0.        , 0.        ,\n",
       "        0.21996303, 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'split2_test_recall': array([0.00739372, 0.11645102, 0.07948244, 0.        , 0.        ,\n",
       "        0.23659889, 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'split3_test_recall': array([0.00924214, 0.10720887, 0.07393715, 0.        , 0.        ,\n",
       "        0.23844732, 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'split4_test_recall': array([0.01111111, 0.0962963 , 0.05740741, 0.        , 0.        ,\n",
       "        0.21666667, 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'split5_test_recall': array([0.01111111, 0.08703704, 0.05555556, 0.        , 0.        ,\n",
       "        0.22777778, 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'split6_test_recall': array([0.01296296, 0.08148148, 0.0537037 , 0.        , 0.        ,\n",
       "        0.21111111, 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'split7_test_recall': array([0.00555556, 0.07592593, 0.05555556, 0.        , 0.        ,\n",
       "        0.20740741, 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'split8_test_recall': array([0.01296296, 0.10740741, 0.06296296, 0.        , 0.        ,\n",
       "        0.2462963 , 0.        , 0.        , 0.        , 0.        ]),\n",
       " 'split9_test_recall': array([0.00740741, 0.1       , 0.06851852, 0.        , 0.        ,\n",
       "        0.22407407, 0.00185185, 0.        , 0.        , 0.        ]),\n",
       " 'mean_test_recall': array([0.00925344, 0.10065585, 0.06549976, 0.        , 0.        ,\n",
       "        0.22908195, 0.00037003, 0.        , 0.        , 0.        ]),\n",
       " 'std_test_recall': array([0.00262134, 0.01489831, 0.00967664, 0.        , 0.        ,\n",
       "        0.01616348, 0.00074006, 0.        , 0.        , 0.        ]),\n",
       " 'rank_test_recall': array([4, 2, 3, 6, 6, 1, 5, 6, 6, 6]),\n",
       " 'split0_test_roc_auc': array([0.87662169, 0.89012944, 0.88820919, 0.85052532, 0.86905736,\n",
       "        0.89929962, 0.87163394, 0.86335623, 0.85043474, 0.85063751]),\n",
       " 'split1_test_roc_auc': array([0.85086504, 0.86981451, 0.86682611, 0.82473392, 0.84288765,\n",
       "        0.88293959, 0.84785734, 0.84069458, 0.82472954, 0.82473365]),\n",
       " 'split2_test_roc_auc': array([0.85513791, 0.87546543, 0.872691  , 0.82338516, 0.84690344,\n",
       "        0.88715527, 0.84775623, 0.83938809, 0.82348271, 0.82342319]),\n",
       " 'split3_test_roc_auc': array([0.87024317, 0.88985581, 0.88512596, 0.84024937, 0.86024469,\n",
       "        0.90032221, 0.86433449, 0.85416197, 0.84031873, 0.84024554]),\n",
       " 'split4_test_roc_auc': array([0.85862544, 0.87643309, 0.87104134, 0.82301286, 0.84924596,\n",
       "        0.88474436, 0.84950914, 0.83876922, 0.82244387, 0.82294268]),\n",
       " 'split5_test_roc_auc': array([0.8751246 , 0.88945171, 0.88746607, 0.84880856, 0.8668879 ,\n",
       "        0.89967103, 0.86745059, 0.85935548, 0.84845629, 0.84885599]),\n",
       " 'split6_test_roc_auc': array([0.85432149, 0.86871947, 0.86623694, 0.82779313, 0.84631549,\n",
       "        0.88032431, 0.85019245, 0.84082627, 0.82768224, 0.82776572]),\n",
       " 'split7_test_roc_auc': array([0.87518011, 0.89008032, 0.88671546, 0.84541396, 0.86868588,\n",
       "        0.89620226, 0.86912767, 0.85922198, 0.84543767, 0.84541451]),\n",
       " 'split8_test_roc_auc': array([0.86100927, 0.88149656, 0.87815295, 0.82773378, 0.85328947,\n",
       "        0.89296104, 0.85360789, 0.842109  , 0.82811868, 0.82774392]),\n",
       " 'split9_test_roc_auc': array([0.86705212, 0.8843452 , 0.88076075, 0.83271376, 0.85883269,\n",
       "        0.89511336, 0.85951367, 0.84947474, 0.83340146, 0.83270869]),\n",
       " 'mean_test_roc_auc': array([0.86441808, 0.88157915, 0.87832258, 0.83443698, 0.85623505,\n",
       "        0.89187331, 0.85809834, 0.84873576, 0.83445059, 0.83444714]),\n",
       " 'std_test_roc_auc': array([0.00914971, 0.00806941, 0.00816707, 0.01028835, 0.00936428,\n",
       "        0.00709952, 0.00895262, 0.00907928, 0.01026042, 0.01031735]),\n",
       " 'rank_test_roc_auc': array([ 4,  2,  3, 10,  6,  1,  5,  7,  8,  9])}"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(CV.cv_results_['mean_test_accuracy'])\n",
    "print(CV.cv_results_['mean_test_f1'])\n",
    "CV.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "d51f54c1-11c3-4625-bd7e-e9f370953325",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>income</th>\n",
       "      <th>name_email_similarity</th>\n",
       "      <th>prev_address_months_count</th>\n",
       "      <th>current_address_months_count</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>days_since_request</th>\n",
       "      <th>intended_balcon_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>zip_count_4w</th>\n",
       "      <th>velocity_4w</th>\n",
       "      <th>bank_branch_count_8w</th>\n",
       "      <th>date_of_birth_distinct_emails_4w</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>credit_risk_score</th>\n",
       "      <th>email_is_free</th>\n",
       "      <th>housing_status</th>\n",
       "      <th>phone_home_valid</th>\n",
       "      <th>has_other_cards</th>\n",
       "      <th>proposed_credit_limit</th>\n",
       "      <th>foreign_request</th>\n",
       "      <th>session_length_in_minutes</th>\n",
       "      <th>device_os_other</th>\n",
       "      <th>device_os_linux</th>\n",
       "      <th>device_os_windows</th>\n",
       "      <th>device_os_macintosh</th>\n",
       "      <th>device_os_x11</th>\n",
       "      <th>keep_alive_session</th>\n",
       "      <th>device_distinct_emails_8w</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>566543</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.129004</td>\n",
       "      <td>56</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.016274</td>\n",
       "      <td>-0.760933</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2034</td>\n",
       "      <td>4847.050264</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.150540</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636294</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.231047</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>-1.319822</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1076</td>\n",
       "      <td>4801.842797</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.680771</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82003</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.550407</td>\n",
       "      <td>-1</td>\n",
       "      <td>324</td>\n",
       "      <td>50</td>\n",
       "      <td>0.028341</td>\n",
       "      <td>-0.604352</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1228</td>\n",
       "      <td>5519.625841</td>\n",
       "      <td>174</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.389204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474606</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.682156</td>\n",
       "      <td>-1</td>\n",
       "      <td>252</td>\n",
       "      <td>40</td>\n",
       "      <td>0.019537</td>\n",
       "      <td>-0.983700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1239</td>\n",
       "      <td>4377.519574</td>\n",
       "      <td>2119</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.341758</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515774</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.278175</td>\n",
       "      <td>98</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>0.517795</td>\n",
       "      <td>-0.709431</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1049</td>\n",
       "      <td>4312.921908</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.257548</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391463</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.479511</td>\n",
       "      <td>-1</td>\n",
       "      <td>128</td>\n",
       "      <td>40</td>\n",
       "      <td>0.011465</td>\n",
       "      <td>-1.327804</td>\n",
       "      <td>2.0</td>\n",
       "      <td>831</td>\n",
       "      <td>3706.417522</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.431931</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397069</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.128094</td>\n",
       "      <td>-1</td>\n",
       "      <td>63</td>\n",
       "      <td>60</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>-0.930445</td>\n",
       "      <td>1.0</td>\n",
       "      <td>994</td>\n",
       "      <td>5567.490719</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.483882</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311252</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.293755</td>\n",
       "      <td>-1</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>0.030686</td>\n",
       "      <td>-1.216027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2044</td>\n",
       "      <td>6324.589990</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.938890</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417972</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.535390</td>\n",
       "      <td>-1</td>\n",
       "      <td>241</td>\n",
       "      <td>50</td>\n",
       "      <td>0.003818</td>\n",
       "      <td>-0.463912</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1063</td>\n",
       "      <td>3089.844367</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.126449</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408241</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.821590</td>\n",
       "      <td>-1</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0.013145</td>\n",
       "      <td>98.680868</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5236</td>\n",
       "      <td>6349.689681</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.667454</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104220 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        income  name_email_similarity  prev_address_months_count  \\\n",
       "566543     0.8               0.129004                         56   \n",
       "636294     0.1               0.231047                         31   \n",
       "82003      0.7               0.550407                         -1   \n",
       "474606     0.4               0.682156                         -1   \n",
       "515774     0.9               0.278175                         98   \n",
       "...        ...                    ...                        ...   \n",
       "391463     0.9               0.479511                         -1   \n",
       "397069     0.6               0.128094                         -1   \n",
       "311252     0.8               0.293755                         -1   \n",
       "417972     0.9               0.535390                         -1   \n",
       "408241     0.8               0.821590                         -1   \n",
       "\n",
       "        current_address_months_count  customer_age  days_since_request  \\\n",
       "566543                            10            30            0.016274   \n",
       "636294                             3            20            0.007882   \n",
       "82003                            324            50            0.028341   \n",
       "474606                           252            40            0.019537   \n",
       "515774                            20            40            0.517795   \n",
       "...                              ...           ...                 ...   \n",
       "391463                           128            40            0.011465   \n",
       "397069                            63            60            0.005348   \n",
       "311252                            41            30            0.030686   \n",
       "417972                           241            50            0.003818   \n",
       "408241                            50            50            0.013145   \n",
       "\n",
       "        intended_balcon_amount  payment_type  zip_count_4w  velocity_4w  \\\n",
       "566543               -0.760933           1.0          2034  4847.050264   \n",
       "636294               -1.319822           1.0          1076  4801.842797   \n",
       "82003                -0.604352           3.0          1228  5519.625841   \n",
       "474606               -0.983700           1.0          1239  4377.519574   \n",
       "515774               -0.709431           1.0          1049  4312.921908   \n",
       "...                        ...           ...           ...          ...   \n",
       "391463               -1.327804           2.0           831  3706.417522   \n",
       "397069               -0.930445           1.0           994  5567.490719   \n",
       "311252               -1.216027           1.0          2044  6324.589990   \n",
       "417972               -0.463912           1.0          1063  3089.844367   \n",
       "408241               98.680868           3.0          5236  6349.689681   \n",
       "\n",
       "        bank_branch_count_8w  date_of_birth_distinct_emails_4w  \\\n",
       "566543                    10                                10   \n",
       "636294                    12                                11   \n",
       "82003                    174                                 2   \n",
       "474606                  2119                                 2   \n",
       "515774                    35                                11   \n",
       "...                      ...                               ...   \n",
       "391463                     1                                 9   \n",
       "397069                    10                                 3   \n",
       "311252                     6                                 5   \n",
       "417972                    19                                 5   \n",
       "408241                    19                                 5   \n",
       "\n",
       "        employment_status  credit_risk_score  email_is_free  housing_status  \\\n",
       "566543                0.0                109              1             2.0   \n",
       "636294                0.0                 96              1             2.0   \n",
       "82003                 1.0                218              0             0.0   \n",
       "474606                0.0                114              0             4.0   \n",
       "515774                0.0                 53              0             0.0   \n",
       "...                   ...                ...            ...             ...   \n",
       "391463                0.0                 83              1             2.0   \n",
       "397069                2.0                108              1             2.0   \n",
       "311252                0.0                 36              0             4.0   \n",
       "417972                0.0                252              0             0.0   \n",
       "408241                1.0                222              1             2.0   \n",
       "\n",
       "        phone_home_valid  has_other_cards  proposed_credit_limit  \\\n",
       "566543                 0                1                  200.0   \n",
       "636294                 0                0                  500.0   \n",
       "82003                  0                0                 1500.0   \n",
       "474606                 1                0                  200.0   \n",
       "515774                 0                0                  500.0   \n",
       "...                  ...              ...                    ...   \n",
       "391463                 0                0                  200.0   \n",
       "397069                 0                0                  200.0   \n",
       "311252                 1                0                 1500.0   \n",
       "417972                 0                0                 1500.0   \n",
       "408241                 0                0                 1500.0   \n",
       "\n",
       "        foreign_request  session_length_in_minutes  device_os_other  \\\n",
       "566543                0                   5.150540                0   \n",
       "636294                0                  15.680771                0   \n",
       "82003                 0                   8.389204                0   \n",
       "474606                0                   3.341758                0   \n",
       "515774                0                   3.257548                0   \n",
       "...                 ...                        ...              ...   \n",
       "391463                0                   6.431931                0   \n",
       "397069                0                  11.483882                0   \n",
       "311252                0                   0.938890                1   \n",
       "417972                0                   4.126449                0   \n",
       "408241                0                   4.667454                0   \n",
       "\n",
       "        device_os_linux  device_os_windows  device_os_macintosh  \\\n",
       "566543                1                  0                    0   \n",
       "636294                0                  0                    1   \n",
       "82003                 0                  1                    0   \n",
       "474606                0                  0                    1   \n",
       "515774                0                  0                    1   \n",
       "...                 ...                ...                  ...   \n",
       "391463                0                  1                    0   \n",
       "397069                1                  0                    0   \n",
       "311252                0                  0                    0   \n",
       "417972                0                  1                    0   \n",
       "408241                0                  0                    1   \n",
       "\n",
       "        device_os_x11  keep_alive_session  device_distinct_emails_8w  month  \n",
       "566543              0                   1                          1      3  \n",
       "636294              0                   1                          1      4  \n",
       "82003               0                   0                          1      2  \n",
       "474606              0                   1                          1      5  \n",
       "515774              0                   0                          1      5  \n",
       "...               ...                 ...                        ...    ...  \n",
       "391463              0                   0                          1      6  \n",
       "397069              0                   0                          1      2  \n",
       "311252              0                   1                          1      0  \n",
       "417972              0                   1                          1      7  \n",
       "408241              0                   1                          1      0  \n",
       "\n",
       "[104220 rows x 29 columns]"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val_under, y_val_under = undersamp.fit_resample(X_val, y_val)\n",
    "\n",
    "X_train_plus = pd.concat([X_train_under, X_val_under])\n",
    "y_train_plus = pd.concat([y_train_under, y_val_under])\n",
    "X_train_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "3529888d-4360-4ab3-88b6-09b2d0ba1e19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reg_lambda': 0.1,\n",
       " 'reg_alpha': 0.1,\n",
       " 'num_leaves': 300,\n",
       " 'n_estimators ': 400,\n",
       " 'min_data_in_leaf': 1600,\n",
       " 'max_depth': 10,\n",
       " 'learning_rate': 0.05}"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "b1e62ec9-69b9-4711-821d-2c7930cdc4f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Info] Number of positive: 5404, number of negative: 67550\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004725 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2669\n",
      "[LightGBM] [Info] Number of data points in the train set: 72954, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.074074 -> initscore=-2.525729\n",
      "[LightGBM] [Info] Start training from score -2.525729\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "CPU times: total: 3.83 s\n",
      "Wall time: 1.79 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-28 {color: black;}#sk-container-id-28 pre{padding: 0;}#sk-container-id-28 div.sk-toggleable {background-color: white;}#sk-container-id-28 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-28 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-28 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-28 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-28 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-28 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-28 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-28 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-28 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-28 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-28 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-28 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-28 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-28 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-28 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-28 div.sk-item {position: relative;z-index: 1;}#sk-container-id-28 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-28 div.sk-item::before, #sk-container-id-28 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-28 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-28 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-28 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-28 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-28 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-28 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-28 div.sk-label-container {text-align: center;}#sk-container-id-28 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-28 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-28\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.05, max_depth=10, min_data_in_leaf=1600,\n",
       "               n_estimators=400, num_leaves=300, reg_alpha=0.1, reg_lambda=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" checked><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.05, max_depth=10, min_data_in_leaf=1600,\n",
       "               n_estimators=400, num_leaves=300, reg_alpha=0.1, reg_lambda=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.05, max_depth=10, min_data_in_leaf=1600,\n",
       "               n_estimators=400, num_leaves=300, reg_alpha=0.1, reg_lambda=0.1)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lgbm = LGBMClassifier(num_leaves=300\\\n",
    "                      ,n_estimators=400\\\n",
    "                      ,min_data_in_leaf=1600\\\n",
    "                      ,max_depth=10\\\n",
    "                      ,learning_rate=0.05\n",
    "                      ,reg_lambda=0.1\n",
    "                      ,reg_alpha=0.1)\n",
    "lgbm.fit(X_train_under,y_train_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e73c01-33a6-49cd-a9e1-84ef0c716b03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "cfe6cc0b-acf7-4572-ade2-bb207aa3b59b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n"
     ]
    }
   ],
   "source": [
    "y_pred_val = lgbm.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "51bd3745-5b36-461c-ac0a-34fd98140a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanced Accuracy: 0.6413519398192931\n",
      "Accuracy: 0.9788904761904762\n",
      "\u001b[1mF1 score: 0.2363479758828596\u001b[0m\n",
      "Precision: 0.19661794210375466\n",
      "Recall: 0.29620034542314333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "Balanced Accuracy: {balanced_accuracy_score(y_val,y_pred_val)}\n",
    "Accuracy: {accuracy_score(y_val,y_pred_val)}\n",
    "\\033[1mF1 score: {f1_score(y_val,y_pred_val)}\\033[0m\n",
    "Precision: {precision_score(y_val,y_pred_val)}\n",
    "Recall: {recall_score(y_val,y_pred_val)}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "364f0313-ef3b-444a-af3a-e3b42d32893c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reg_lambda': 0.1,\n",
       " 'reg_alpha': 0.1,\n",
       " 'num_leaves': 300,\n",
       " 'n_estimators ': 400,\n",
       " 'min_data_in_leaf': 1600,\n",
       " 'max_depth': 10,\n",
       " 'learning_rate': 0.05}"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "1b86e432-647a-4dba-946d-67116f29b769",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n",
      "[LightGBM] [Info] Number of positive: 7720, number of negative: 96500\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006348 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2670\n",
      "[LightGBM] [Info] Number of data points in the train set: 104220, number of used features: 28\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.074074 -> initscore=-2.525729\n",
      "[LightGBM] [Info] Start training from score -2.525729\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-30 {color: black;}#sk-container-id-30 pre{padding: 0;}#sk-container-id-30 div.sk-toggleable {background-color: white;}#sk-container-id-30 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-30 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-30 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-30 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-30 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-30 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-30 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-30 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-30 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-30 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-30 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-30 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-30 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-30 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-30 div.sk-item {position: relative;z-index: 1;}#sk-container-id-30 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-30 div.sk-item::before, #sk-container-id-30 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-30 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-30 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-30 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-30 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-30 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-30 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-30 div.sk-label-container {text-align: center;}#sk-container-id-30 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-30 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-30\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.05, max_depth=10, min_data_in_leaf=1600,\n",
       "               n_estimators=400, num_leaves=300, reg_alpha=0.1, reg_lambda=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" checked><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.05, max_depth=10, min_data_in_leaf=1600,\n",
       "               n_estimators=400, num_leaves=300, reg_alpha=0.1, reg_lambda=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.05, max_depth=10, min_data_in_leaf=1600,\n",
       "               n_estimators=400, num_leaves=300, reg_alpha=0.1, reg_lambda=0.1)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm = LGBMClassifier(num_leaves=300\\\n",
    "                      ,n_estimators=400\\\n",
    "                      ,min_data_in_leaf=1600\\\n",
    "                      ,max_depth=10\\\n",
    "                      ,learning_rate=0.05\n",
    "                      ,reg_lambda=0.1\n",
    "                      ,reg_alpha=0.1)\n",
    "lgbm.fit(X_train_plus,y_train_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "e7db20b6-9b25-4362-833d-92da5e370e63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n"
     ]
    }
   ],
   "source": [
    "y_pred = lgbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "1f2a7de3-54f3-4179-a84c-05ad38715de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9794, 0.24041297935103242, 0.20261031696706028, 0.2955575702629193)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred), f1_score(y_test,y_pred), precision_score(y_test,y_pred), recall_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "d1a34663-3898-46a7-9b43-5cbae5aa7c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanced Accuracy: 0.6412922385223613\n",
      "Accuracy: 0.9794\n",
      "\u001b[1mF1 score: 0.24041297935103242\u001b[0m\n",
      "Precision: 0.20261031696706028\n",
      "Recall: 0.2955575702629193\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'''\n",
    "Balanced Accuracy: {balanced_accuracy_score(y_test,y_pred)}\n",
    "Accuracy: {accuracy_score(y_test,y_pred)}\n",
    "\\033[1mF1 score: {f1_score(y_test,y_pred)}\\033[0m\n",
    "Precision: {precision_score(y_test,y_pred)}\n",
    "Recall: {recall_score(y_test,y_pred)}\n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practica0",
   "language": "python",
   "name": "practica0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
