{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f990a58-022d-47a9-8fc5-e125ffe52780",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407f5fb5-36c2-4fd6-9ff6-df30d337cbe2",
   "metadata": {},
   "source": [
    "# Análisis Exploratorio de Datos (EDA: Exploratory Data Analisys):\n",
    "\n",
    "**Toda la documentación de este cap en /Machine_Learning/docs/4.EDA_tratamiento_vars_encoding/...**\n",
    "\n",
    "Diferencia instalaciones Conda VS Pip:\n",
    "* Con Conda SI se actualizan las dependencias con otras librerías, cosa que con PIP NO pasa!\n",
    "\n",
    "## Fases de exploración (Slide):\n",
    "\n",
    "0. DEFINIR EL PROBLEMA A RESOLVER!\n",
    "1. Exploración inicial de las variables\n",
    "2. Separación en train y test\n",
    "3. Tratamiento de missing, outlier y correlaciones\n",
    "4. Codificación de las variables categóricas\n",
    "5. Escalado de los datos (si es necesario)\n",
    "6. Selección de variables input del modelo (eliminación de colinealidad si es necesario)\n",
    "\n",
    "Lo que hacemos técnicamente, osea los pasos NO son lo más importante, **sino la explicación conceptual que sacamos de cada paso del análisis!**\n",
    "\n",
    "### 1. Definición del problema a resolver\n",
    "\n",
    "* ¿Cual es el problema? --> Definición en ámbito de Negocio. Supervisado o no supervisado? Clasificación o regresión?\n",
    "    - Por ej, si voy a dar un préstamo, sería seguramente supervisado\n",
    "    - Clasificación sería en este caso, pq sería 1 o 0. Si fuese score crediticio alomejor sería regresión, habría que ver...\n",
    "* Acción que necesitamos para solucionar el problema --> Nos vamos poniendo a ver COMO solucionarlo\n",
    "* ¿Cuales son las VARIABLES disponibles? --> Que tablas necesito cruzar\n",
    "* ¿En que momento se va a implantar el modelo? --> Cuando el cliente me da todos sus datos? O dsps de un tiempo? Alomejor no tengo las variables en ese momento en el que se requiere el análisis! Es importante ver esto.\n",
    "* ¿Como se va a validar el modelo?\n",
    "\n",
    "### 2. Exploración general de las tablas\n",
    "\n",
    "* Ver las DIMENSIONES y VARIABLES\n",
    "* Ver si todas las variables están disponibles en el momento\n",
    "* VER VARIABLES OBJETIVO (En este caso las etiquetas de un modelo supervisado). Hay balance de 0 y 1 o no?\n",
    "* Análisis de Nulls/Valores faltantes. Que variables, que instancias, etc.\n",
    "* Distinción de variables numéricas y categóricas, y se decide procesos para tratarlas!\n",
    "* Transformaciones iniciales de variables, como formato de fechas, tratamiento de Strings, ETL, etc.\n",
    "\n",
    "¿Como interpretar las probabilidades de un modelo?\n",
    "\n",
    "La idea es añadir variables al procentaje base para personalizar los casos a cada input de datos y que el output sea lo más preciso posible en cuanto a una probabilidad, de pago o inpago en este caso x ej.\n",
    "\n",
    "# Notebooks:\n",
    "\n",
    "#### Importante DIVIDIR los notebooks! Por ejemplo, hasta acá podría ser un notebook, exploración básica. Explotar archivo y mandarlo\n",
    "\n",
    "**Clave: NOTEBOOKS nombrados así:**\n",
    "01_EDA_base\n",
    "02_Train_test_split y demás\n",
    "\n",
    "**Clave: nombrar documentos como lo que son!**\n",
    "\n",
    "pd_df1\n",
    "pd_df2\n",
    "list_lista1\n",
    "y así...\n",
    "\n",
    "#### 1. Títulos, descripción de lo que va el notebook\n",
    "#### 2. Importar librerías y formatos\n",
    "#### 3. FUNCIONES!\n",
    "\n",
    "Se pueden copiar y pegar en cada notebook.\n",
    "\n",
    "Pero tmb se puede pasar una función a un .py e importarla en cada notebook!\n",
    "\n",
    "Esto se hace así: **func_prueba.py**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05213ac5-080b-48dd-b313-2b86295b8574",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import func_prueba\n",
    "## si quisiera poner las funciones en otro directorio:\n",
    "\n",
    "#import sys\n",
    "#sys.append('./functions')\n",
    "\n",
    "# ver dsps bien como se hace!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "561cb080-dd58-4e8e-9b2f-193985286416",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# con ctrl+i podemos ver info de la función como con todas las demás funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bc0dd25-7090-481c-b63c-9f4670bc2786",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Faltan argumentos por pasar a la función\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_prueba.dame_variables_categoricas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccddf9e8-5f79-4042-a03f-60175989ea3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "En esta función lo que hace es ver los uniques de cada variable y si es tiene menos de 100 valores únicos te tira las que son al menos candidatas\n",
    "a ser categóricas. Obviamente hablando de numéricas, si son Strings por ejemplo, ya te las trae como categóricas. Está lindo\n",
    "\n",
    "4. Importar **DataSet**! (puede ser en partes)\n",
    "\n",
    "5. Ver que variables son futuras y cuales ya tenemos. Las futuras las tenemos que sacar si no se pueden usar al momento en que se aplican al modelo...\n",
    "\n",
    "6. Ojo al unir las tablas! Tiene que haber **claves** en los que las tablas son **filas ÚNICAS**... Puede haber más de un index, ojo con eso. Pero bueno, que el index tiene que ser único básicamente.\n",
    "\n",
    "7. **ELIMINAR DUPLICADOS**: Ver como se hace en el código de ejemplo con .drop_duplicates()\n",
    "\n",
    "8. **VER LOS TIPOS DE LAS VARIABLES!** con .to_dict() lo puedo pasar a diccionario y que se vea mejor.\n",
    "\n",
    "9. Ver **COMO cambiar las variables de tipo**, sobre todo de Strings a Numéricas, con o sin encoding...\n",
    "\n",
    "10. Contar el **% de Nulos!**\n",
    "\n",
    "11. Exploración de **VARIABLE OBJETIVO**. Ver cual es el objetivo que quiero y seguramente lo tenga que convertir a Booleano, para ver como lo voy a querer categorizar! En este caso que hablamos de categorías obviamente. Por ej, en el caso ejemplo, SOLO quiero ver si son Fully Paid o Charged Off!\n",
    "\n",
    "12. Tratamiento de **Nulls** con *Threshold*! (% de nulls que acepto...)\n",
    "\n",
    "13. Hasta ahora tratamos nulls por COLUMNA, pero tmb hay que ver por FILAS! **Tengo que ver si hay filas en los que no tengo datos y sacarlos!**\n",
    "\n",
    "14. Veo variables categóricas Y LAS CAMBIO DE TIPO CON **.astype('category')**\n",
    "\n",
    "15. Transformo las variables y las proceso inicialmente!\n",
    "\n",
    "16. Corto el notebook, exporto lo que tengo y lo sigo en otro!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da93261-fb88-4124-9043-a76d3862fa27",
   "metadata": {},
   "source": [
    "### 3. Train_Test_Split\n",
    "\n",
    "OJO! Que NO haya desbalanceo cuando hago el TTS: **Separación estratificada en SKL!** --> **En la práctica hay que hacerlo!**\n",
    "\n",
    "### IMPORTANTE:\n",
    "**Hay que separar en Train y Test ANTES de realizar cualquier transformación que requiera cálculos en la columna!!!**\n",
    "\n",
    "Osea, los missing y outliers tienen que ser sustituídos DESPUÉS de haber dividido en TRAIN y TEST\n",
    "\n",
    "EN CASO DE USAR UN ESTADÍSTICO PARA LA SUSTITUCIÓN DE VALORES, NO HAY QUE USAR EL DE TRAIN PARA TRAIN Y TEST PARA TEST, SINO QUE HAY QUE USAR EL DE TRAIN PARA AMBOS!! Osea, la mediana del TRAIN lo tengo que usar para sustituir en AMBOS, osea si quiero rellenar los valores nulls del TEST, uso con la median del TRAIN!!! Esto es mucho muy importante!\n",
    "\n",
    "(Esto está en las Slides, leer!)\n",
    "\n",
    "\n",
    "### 4. Tratamiento de OUTLIERS (!= a nulls)\n",
    "\n",
    "Es necesario analizar la relacion con la variable objetivo y analizar su contexto. Hay una manera matemática standard de los Outliers (ver slides!)\n",
    "\n",
    "Empezamos aplicando la fórmula y dsps la vemos EN CONTEXTO. Depende del análisis si los necesito o si los puedo sacar!\n",
    "\n",
    "\n",
    "### Separación en Train_Test ESTRATIFICADO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5b4efa-4509-4764-8ed7-4fb81b57b8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_pd_loan, X_pd_loan_test, y_pd_loan, y_pd_loan_test = train_test_split(pd_loan.drop('loan_status',axis=1), \n",
    "                                                                     pd_loan['loan_status'], \n",
    "                                                                     stratify=pd_loan['loan_status'], \n",
    "                                                                     test_size=0.2)\n",
    "pd_loan_train = pd.concat([X_pd_loan, y_pd_loan],axis=1)\n",
    "pd_loan_test = pd.concat([X_pd_loan_test, y_pd_loan_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aeb9d11d-ee24-4a1a-b726-4b032a8b5223",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1413921155.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[19], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    , test_size=0.2)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Acá está la clave:\n",
    "train_test_split(pd_loan.drop('loan_status',axis=1)\n",
    "                 , pd_loan['loan_status']\n",
    "                 , stratify=pd_loan['loan_status'],  # ESTA ES LA CLAVE! COMO QUIERO QUE ESTRATIFIQUE!\n",
    "                 , test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91ca014e-19b8-4b6d-acfb-a498b46434a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "720db312-4600-4568-918f-f0714762bae7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1230761737.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[20], line 4\u001b[1;36m\u001b[0m\n\u001b[1;33m    , test_size=0.2)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "train_test_split(pd_loan.drop('loan_status',axis=1)\n",
    "                 , pd_loan['loan_status']\n",
    "                 , stratify=pd_loan['loan_status'],  # ESTA ES LA CLAVE! COMO QUIERO QUE ESTRATIFIQUE!\n",
    "                 , test_size=0.2)\n",
    "\n",
    "# con ctrl+i o shift+tab veo info de la function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e6d875-eb7d-460e-8c71-44149dd26f00",
   "metadata": {},
   "source": [
    "# Práctica:\n",
    "\n",
    "descargar el DataSet de Kaggle y leer toda la documentación en el Anuncio de Diego!!! Da contexto sobre toda la info del DataSet! Que columnas tiene y que significan, y demás! **ESTO ES MUY CLAVE!!!**\n",
    "\n",
    "# Authomatic_EDA.ipynb --> Archivo clave para la Práctica!!! Mucho MUY importante leer todo esto!\n",
    "\n",
    "EDA Automático con SweetViz por ejemplo, info de todo el DataSet y variables, etc etc etc!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9da8ef-bb5b-446d-97e9-98ede9c5dd36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a9229d-d619-4bf6-a50e-c76ed6a9ddc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c16fe6-dcc3-4fb5-bb82-f58428c07fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5466ae2d-9354-49c8-8971-f964d7eedcb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f0be13-e129-49ea-ae7c-46cad6be41ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
