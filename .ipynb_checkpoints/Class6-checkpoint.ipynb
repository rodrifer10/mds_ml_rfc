{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15d3c8d9-6c63-4a48-a22b-2a40ec803e99",
   "metadata": {},
   "source": [
    "# Class 6\n",
    "\n",
    "# Seguimos con el EDA\n",
    "* Un BoxPlot dice lo mismo que un gráfico de una distribución! (ver Slides!)\n",
    "\n",
    "## Tratamiento de Outliers\n",
    "\n",
    "Puede haber outliers POR FILA, es más difícil pero se puede hacer con algorítmos como dbscan!\n",
    "\n",
    "(reparar la clase4)\n",
    "\n",
    "## Tratamiento de Missing\n",
    "\n",
    "* Si son muy muchos en la variable, la eliminamos, tipo 98% missing chau...\n",
    "* Si vamos a mantener la variable, debemos SUSTITUÍR los valores Missing\n",
    "    - Si la variable es Categórica, los Missings pueden si representar algo! Muchas veces se rellena con una categoría 'No value', o 'Sin valor'. Si veo que NO influyen en nada, alomejor se podría reemplazar por la moda de las cats, hay que ver!\n",
    "    - Si la var el Numerical, habría que ver si lo rellenamos por la media, mediana, max o min, o por algún valor que sepamos que representa el missing, como -99 en edad o -1, depende...\n",
    "        - Estos valores extremos pueden servir en algorítmos de clasificación, como los Trees, en ese caso va bien pq los va a cortar solos\n",
    "        - Pero OJO, que en una regresión o algo si puede afectar! En vez de edad -99 puede ser -1, hay que ver el tratamiento que se les da...\n",
    "\n",
    "* ANTES de sacar cualq cosa, hay que ver que relación tienen con la variable Target!\n",
    "\n",
    "## Tratamiento de correlaciones\n",
    "\n",
    "* Correlación: Que varíen en proporciones muy similares, ya sea positiva o negativa!\n",
    "* Solo se pueden aplicar las corr de pearson a variables CONTINUAS (NO CATEGÓRICAS, por más q sean numéricas!)\n",
    "* En REGRESIONES sobre todo, cualq variable correlacionada HAY QUE ELIMINAR HASTA QUEDARSE SOLO CON UNA MÁS REPRESENTATIVA.\n",
    "* Corr mayor a 0.75, nos quedamos solo con una!\n",
    "\n",
    "#### PARA LA PRÁCTICA PONER TODAS LAS CORRELACIONES Y COMENTARLAS!\n",
    "\n",
    "# MUY IMPORTANTE EN LA PRÁCTICA!!! QUE SEA ESTRATIFICADO EL TRAIN_TEST_SPLIT!!!\n",
    "# PARA QUE MANTENGAN LAS PROPORCIONES (PORCENTAJES DE 0 Y 1) EN LA VARIABLE OBJETIVO!!!!!!!!!!!!!!!\n",
    "# ESTO SIEMPRE ES MUY MUCHO MUY IMPORTANTE\n",
    "\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_pd_loan, X_pd_loan_test, y_pd_loan, y_pd_loan_test = train_test_split(pd_loan.drop('loan_status',axis=1), \n",
    "                                                                     pd_loan['loan_status'], \n",
    "                                                                     stratify=pd_loan['loan_status'], \n",
    "                                                                     test_size=0.2)\n",
    "```\n",
    "Como vemos, stratify=df['VARIABLE TARGET!']\n",
    "\n",
    "\n",
    "### Sumar nros por filas y columnas:\n",
    "\n",
    "```python\n",
    "pd_series_null_columns = pd_loan_train.isnull().sum().sort_values(ascending=False)\n",
    "pd_series_null_rows = pd_loan_train.isnull().sum(axis=1).sort_values(ascending=False)\n",
    "print(pd_series_null_columns.shape, pd_series_null_rows.shape)\n",
    "```\n",
    "\n",
    "#### El gráfico doble que analiza cada variable es MUY CLAVE, es genial! Muestra distribución y boxplot según los valores del Target!!!\n",
    "\n",
    "## Tratamiento de variables Continuas VS Categóricas\n",
    "\n",
    "* Llegado el momento las vamos a separar por varias cosas:\n",
    "    - Las numéricas pueden reemplazar sus outliers parecido entre ellas, categóricas NO, hay que ver cada caso y q categoría poner...\n",
    "    - Para las numericas puede sacarse la correlacion\n",
    "    - hay más...\n",
    "\n",
    "Formar de separarlas: por el unique(), las categóricas deberían tener pocas y numéricas muchas (ver funciñon)\n",
    "\n",
    "* Hay que ver si la distribución de la variable Target en Outliers se mantiene o no! Osea, por cada variable, ver cantidad de outliers y ver q distribución de 1 y 0 tienen de la variable objetivo!\n",
    "\n",
    "* El % de la fórmula para determinar Outliers es MODIFICABLE, no es siempre 1.5 \n",
    "\n",
    "\n",
    "### Muy bueno. Saca LAS VARIABLES MÁS CORRELACIONADAS entre sí! Esto puede servir para ordernar el HeatMap tmb! CLAVE:\n",
    "```python\n",
    "corr = pd_loan_train[list_var_continuous].corr('pearson')\n",
    "new_corr = corr.abs()\n",
    "new_corr.loc[:,:] = np.tril(new_corr, k=-1) # below main lower triangle of an array\n",
    "new_corr = new_corr.stack().to_frame('correlation').reset_index().sort_values(by='correlation', ascending=False)\n",
    "new_corr[new_corr['correlation']>0.6]\n",
    "```\n",
    "\n",
    "# Para tratar los Nulls es MUY CLAVE ver el archivo 02_Tratamiento_Correlaciones_Outliers_nulls... Ahí están todas las opciones y métodos para poder tratar nulls y outliers!!!\n",
    "\n",
    "La función `.fillna()` permite rellenar nos nulls:\n",
    "```python\n",
    "list_vars = list(set(list_var_continuous)-set(['revol_util']))\n",
    "pd_loan_train[list_vars] = pd_loan_train[list_vars].fillna(-99)\n",
    "pd_loan_test[list_vars] = pd_loan_test[list_vars].fillna(-99)\n",
    "```\n",
    "\n",
    "## Se puede usar KNN para rellenar tmb!\n",
    "* Se usa para rellenar los Nulls con los valores de la row más parecida al resto de los datos de la row que se tiene\n",
    "* KNN agrupa en base a Euclidian Distance entre los individuos (rows) de un DataSet\n",
    "* OJO, muchas veces no es necesario usar un algorítmo tan complejo para fillear los nulls... Hay que ver que es mejor y más eficiente!\n",
    "\n",
    "\n",
    "# Exploración de variables categóricas\n",
    "* Tmb ver en el archivo 02_Tratamiento_Correlaciones_Outliers_nulls... Es importante\n",
    "* Como no se puede ver la corr, se puede usar la función de Pandas `pd.crosstab()`, q está muy buena para ver como se cruzan las variables categóricas más importantes!\n",
    "* No hace falta hacerlo con tooodas, sino para las variables que más se han diferenciado o resaltado en el gráfico descriptivo que vimos arriba!\n",
    "\n",
    "\n",
    "### V de Cramer:\n",
    "\n",
    "LO uso para ver un índice similar al de correlacion en matrices como esta de pd.crosstab(), osea que **Puedo ver la correlación entre dos variables categóricas! Si es cercano  a 1, va a haber correlación!**\n",
    "\n",
    "* Si saco la V de Cramer para todas las variables categóricas, tmb la voy a poder dibujar como un HeatMap! Estaría muy interesante ver como hacerlo para la práctica!\n",
    "\n",
    "### No olvidar, si rellené en el DataSet de Train, relleno igual en el DataSet de Test!!!\n",
    "\n",
    "\n",
    "# Codificación de variables categóricas:\n",
    "\n",
    "Siempre que se puedan cambiar categorías a números, en variables categóricas ordinales x ej, hacerlo, mejor.\n",
    "\n",
    "Las categóricas pueden ser:\n",
    "* Ordinales (meses x ejemplo)\n",
    "* Nominales\n",
    "\n",
    "## 1. One Hot Encoding\n",
    "\n",
    "Codificar variables categóricas\n",
    "\n",
    "La idea es SIEMPRE PONER N-1 CATEGORÍAS. Osea, si hay 5, la idea no es hacer un OHE de las 5, sino de las 4. Porque la quinta daría correlación! **LA función de SKL devuelve n-1 variables**. La última variable sería el ELSE, osea si no es nada de eso, es lo otro!\n",
    "\n",
    "### En TREES NO HACE FALTA Q SEA N-1 PERO EN REGRESIONES X EJ SI, pq penalizan correlaciones!\n",
    "\n",
    "Yo se que valor de la columna va a ser!\n",
    "\n",
    "### Problema del OHE: Agrego alta Dimensionalidad al modelo! Solo para cuando hay POCAS categorías!\n",
    "\n",
    "## 2. Ordinal Encoding\n",
    "Lo puedo usar para codificar las variables Ordinales!\n",
    "\n",
    "\n",
    "## 3. Target Encoding\n",
    "\n",
    "Este método es muy bueno pq no crea muchas más columnas, sino que genera un código con el algorítmo en base a la variable objetivo!!!\n",
    "\n",
    "(diferente al label encoding, es mejor!)\n",
    "\n",
    "Este es de la libería categorialencoding, SKL tiene las de OneHotEncoding y OrdinalEncoding\n",
    "\n",
    "Creamos **UNA columna en vez de tantas dimensiones como categorías...** \n",
    "\n",
    "\n",
    "## Hay más encodings, como el Frequency por ejemplo...\n",
    "\n",
    "# Tanto One Hot Encoding como Target Encoding deben aplicarse primero al Train y aplicarlo dsps al Test!\n",
    "\n",
    "\n",
    "# .fit se aplica en el Train y .transform en el test!!! Esto es CLAVE. No deberíamos usar .fit_transform en principio siempre q tengamos Train y Test!\n",
    "Esto es pq el `.fit()` va a entrenar el modelo con el Train, va a guardar todo lo del Train y el `.transform()` se lo aplico al Test para q haga los mismos ajustes allí!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# <font color='deepskyblue'> APLICAR NOTEBOOK 1 Y 2 A LA PRÁCTICA! </font>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9e2ae2-4a59-42ec-8ed1-eb712dd96323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08b1931-df1b-43e6-8faf-158efc0bba09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48bb900-e17c-41ee-b794-c8f4bd01f529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd3ac22-3c79-46c8-b26d-a0138b694ce4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a63554e-be52-4ef4-8024-e071bbe1ec54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed02152-044e-4802-b32f-6b21a0f77ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e515f5-de63-440f-88c5-250f274c9f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b9bc54-fe4f-4c47-9e2c-9ce79f57e27c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
