{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2a7a368-f00e-4566-8b00-c550e50f0e08",
   "metadata": {},
   "source": [
    "# Práctica\n",
    "\n",
    "1. Modelo base es DSPS del oversampling y del Featuring Selecting\n",
    "\n",
    "Pasos:\n",
    "1. EDA\n",
    "2. Encoding\n",
    "3. Estandarizar!! (Regre logística! --> recordar penalizaciones de Ridge o Lasso)\n",
    "4. OverSampling\n",
    "5. Featuring Selection --> empezamos los modelos x los árboles de decisión... (en realidad por Random Forest, XGBoost, etc)\n",
    "    - Tmb hacer selección de variables por Ridge o Lasso!\n",
    "6. Ajustar los modelos\n",
    "7. Evualuar resultado --> EVALUAR RESULTADOS EN TEST!\n",
    "    - Acá voy a ir y volviendo entre el 7 y el 6 muchas veces!!\n",
    "    - Acá tmb tenemos que probar sacando o dejando Outliers, missings y demás!!!\n",
    "\n",
    "\n",
    "Utilizo el scaled si o si para regresiones, para los otros es lo mismo normal o scaled\n",
    "\n",
    "* En Redes Neuronales siempre hay que normalizar!\n",
    "\n",
    "Puede q nos pase q tengamos una curva ROC de 1 y el modelo sea una cagada ehh, ojo...\n",
    "\n",
    "Se crea en base a la confussion matrix, con el ratio de verdaderos positivos y de verdaderos negativos...\n",
    "\n",
    "RTP = TP / (TP+TN)\n",
    "RFP = ?? revisar\n",
    "\n",
    "No nos interesa solo pegarle, nos interesa saber que es más importante, si en un 1 decir q es un 0 o en un 0 decir q es un uno, depende situaciones..\n",
    "\n",
    "Osea, prefiero fallar muy poco y pegarle a pocos o fallar más y pegarle a más? Precisión básicamente...\n",
    "\n",
    "Bias vs Variance, Precision y Recall... etc\n",
    "\n",
    "- Utilizar probabilidades! Elijo intentar pegarle a las que mayor PROBABILIDAD tenga!!!\n",
    "    - **usar predict_proba() más que predict!** Para elegir el threshold en el que pongo el corte!\n",
    "    - Con estas probabilidades armo las curvas!\n",
    "- Acá entra lo de curva ROC y sobre todo lo de PRECISION-SENSITIVIDAD (precision-recall)! --> buscar estas (ESTO ES PARA MODELOS DESBALANCEADOS)\n",
    "- La CLAVE y más en estos casos: **CURVA DE GANANCIA***!!!\n",
    "- Todo esto es pq EVALUAR UN MODELO DESBALANCEADO **NO** ES FÁCIL! --> INVESTIGAR SOBRE ESTO! En internet, preguntar al chat, todo lo q se pueda\n",
    "\n",
    "Entonces:\n",
    "1. Hago el modelo\n",
    "2. Calculo la probabilidad!!! Con esto voy a armar las curvas\n",
    "3. Armo y grafico las curvas! (ROC, CUMULATIVE GAIN, etc!)\n",
    "4. Confussion Matrix\n",
    "5. Precision y Recall\n",
    "\n",
    "- CON LAS CURVAS: VER DIFERENCIAS ENTRE LAS CURVAS DE TRAIN Y TEST!! --> SI SON PARECIDAS VAN A ESTAR BIEN PQ SE AJUSTAN A AMBOS\n",
    "- Las ROC en problemas desbalanceados no están buenas pq van a salir muy bien... Por el tema de q si va todo a 1 va a salir bien...\n",
    "- **Ojo!!! Cuando hacemos oversampling NO SON COMPARABLES EL TRAIN Y EL TEST! Pq van a tener diferentes cantidades de 1... Entonces acá las curvas van a ser re distintas...**\n",
    "- Por eso probar sin el sampling y solo estratificado..\n",
    "\n",
    "etc...\n",
    "\n",
    "### ver código de train_facturas en donde calcula las curvas y demás. Ver el gráfico del precision-recall y threshold. Gráfico recall vs precision!\n",
    "- Este gráfico hace threshold (eje x) vs precision/recall...\n",
    "\n",
    "Tenemos que redactar nosotros si nos interesa más detectar muchos 1 y fallar en algunos 0 o al revés...\n",
    "\n",
    "Para Ana es más importante detectar más 1 que 0 pero bueno, habría que ver\n",
    "\n",
    "Y sino, equilibrio, quiero llegar a un equilibrio entre falsos negativos y positivos.\n",
    "\n",
    "- Entocnes pongo el threshold yo y saco la Confussion Matrix!\n",
    "\n",
    "## Cumulative Gain! --> Clave! de SKPlot! --> plot cumulative gain\n",
    "\n",
    "Ordena las probabilidades de mi modelo y grafica \n",
    "\n",
    "Plotea el porcentaje del dataset que cojo (eje x) y cuanto estoy acertando (eje y). Osea No es accuracy sino probabilidades!\n",
    "\n",
    "1. Ordena probabilidades de mayor a menor y ordena el dataset por esto\n",
    "2. Ve cuanto voy acertando con esa muestra del DataSet\n",
    "\n",
    "* Esta curva es CLAVE en datasets desbalanceados!\n",
    "* Probas muy altas normalmente acierta muy bien! pero claro, va bajando la proba y bajan los aciertos\n",
    "\n",
    "La idea es ir jugando con esas probabilidades que sacamos del modelo.\n",
    "\n",
    "El tema es COMO la corto entre 0 y 1 dependiendo cuanto me interesa fallar en 0 y 1 o acertar en 0 y 1...\n",
    "\n",
    "Graficar si o si\n",
    "- ROC\n",
    "- PRC\n",
    "- Cumulative Gain\n",
    "- Confussion Matrix\n",
    "\n",
    "**Clave: funciones para esto! --> Confussion Matrix, cada una de las 3 curvas, etc...**\n",
    "\n",
    "***\n",
    "En trees:\n",
    "\n",
    "feature_importance clave\n",
    "importance_type='Gain' clave\n",
    "\n",
    "Esto me va a dar la importancia de las variables en el modelox --> **SIEMPRE PLOTEARLA EN TODOS LOS ALGORÍTMOS DE ÁRBOLES!**\n",
    "\n",
    "En regresión tmb, siempre plotear los pesos (coeficientes! (w))\n",
    "\n",
    "***\n",
    "\n",
    "**Un notebook por modelo!!!**\n",
    "\n",
    "## Clase de hoy\n",
    "\n",
    "Pasos evaluación del modelo:\n",
    "\n",
    "**TODO ESTO EN TRAIN Y TEST:**\n",
    "\n",
    "0. Sacar importancia de las variables! (Featuring Selection)\n",
    "1. Sacar la probabilidad que le asigna a cada instancia con .predict_proba()\n",
    "2. Hacer las 3 curvas:\n",
    "    1. ROC (NO es buena medida para desbalanceados)\n",
    "    2. PRC\n",
    "    3. Cumulative Gain\n",
    "        * Métricas adicionales: F1 y demás...\n",
    "3. ELEGIR que priorizo! Fallar más o fallar menos, elegir que quiero optimizar!! --> Definir el objetivo del modelado\n",
    "    - En el problema de fraude puede q prefiera categorizar más por 1 q por 0. Porque la empresa puede alomejor poner límites de fraude por ej y demás...\n",
    "    - Recordar que todo tiene que estar dentro de un Bussines Case! Así que debemos contextualizar todo esto si o si!!!\n",
    "4. Poner el threshold de corte para CONVERTIR PROBABILIDADES EN 1 Y 0! --> Esto sale de las curvas!!!\n",
    "    - x<0.1 --> 1\n",
    "    - x>=0.1 --> 0\n",
    "5. Confussion Matrix\n",
    "6. Sacar importancia de variables! (Featuring Selection)\n",
    "\n",
    "***\n",
    "Una vez seleccionamos variables podemos utilizarlas para el resto. Osea, \n",
    "\n",
    "\n",
    "**CLAVE: 01_example_model_...**\n",
    "\n",
    "sklearn plot roc curve y muchas más YA ESTÁN HECHAS!\n",
    "\n",
    "# Clave Featuring Engeneering: MEAN ENCODING! Aplicar al menos para probar!\n",
    "\n",
    "## t-SNE --> A LA PRÁCTICA\n",
    "\n",
    "## Investigar Transformaciones polinomiales, si son útiles o no en problemas como este --> Featuring Engeneering\n",
    "\n",
    "# CROSS VALIDATION --> SI O SI EN LA PRÁCTICA! --> EXPLICAR QUE NO HAY OVERFITTING!!! --> CLAAAVE\n",
    "## Nunca métricas de Training!! --> Solo valen para justificar que NO hay OverFitting comparándolas con el Test!\n",
    "\n",
    "# EN LA PRÁCICA --> EL ESCALADO DE VARIABLES NO HACERLAS SOBRE TODAS! SOBRE LAS ENCODIFICADAS PODRÍA NO APORTAR NADA Y PUEDE Q NO SEA BUENO APLICARLO!!!\n",
    "\n",
    "## Comentar pq elegimos parámetros en los modelos!\n",
    "Por ejemplo en SVM!\n",
    "\n",
    "***\n",
    "# LOS MODELOS PROBARLOS SIN CONFIGURAR HIPERPARÁMETROS Y ESO!\n",
    "# LO HACEMOS CON LOS QUE ELEGIMOS!\n",
    "\n",
    "### Ojo con modelos con Curva ROC 0.9 x ej! O está desbalanceado o algo raro hay...\n",
    "\n",
    "***\n",
    "# BUSQUEDA Y CONFIGURACIÓN DE HIPERPARÁMETROS --> GRID + CROSS VALIDATION SI O SI!\n",
    "\n",
    "\n",
    "***\n",
    "\n",
    "# EL SVM COMO TARDA MUCHO, SE PODRÍA HACER UN EXPERIMENTO APARTE, PROBÁNDOLO AISLADO FUERA DEL PIPELINE CON UN % DEL DATASET DE TRAIN, PARA NO ROMPER TODO...\n",
    "## Enotnces, probarlo con el 20%, documentarlo bien con %%time --> No usamos el SVM como modelo final pq el tiempo de ejecución no me vale!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f116397-9f81-40e0-bc15-0ca406b8424b",
   "metadata": {},
   "source": [
    "***\n",
    "# OJO CON LA SINTAXIS DEL PIPELINE Y EL PARAM_GRID! ES CLAVE ESTO:\n",
    "\n",
    "'nombre_pipeline__n_estimators' --> nombre_pipeline + __ + función creo q es!\n",
    "\n",
    "***\n",
    "\n",
    "# PIPELINE DE TODOS LOS MODELOS!!! --> ME QUEDO CON ALGUNOS Y LOS GRÁFICOS, CURVAS Y DEMÁS LOS PROFUNDIZO EN LOS MODELOS FINALES ELEGIDOS!!! CLAVE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c8de45-f2f4-464b-931a-54ea578a4edf",
   "metadata": {},
   "source": [
    "## CONSTANTES --> PARAMETRIZAR CÓDIGO! --> SEED=SEED X EJEMPLO!\n",
    "\n",
    "## Todas las modificaciones al DataSet de Test tienen que hacerse en un Pipeline!!!\n",
    "# Esto quiere decir que los preprocessings tienen que ir en un Pipeline!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed514ca4-e682-4d93-82d6-59db32be3a14",
   "metadata": {},
   "source": [
    "***\n",
    "## Recordar hacer el modelo base! --> Dsps del oversampling, no va a cambiar nada PQ RECORDAR Q MIDO CON EL TEST! OSEA LAS MÉTRICAS QUE VALEN SON CON EL TEST!\n",
    "\n",
    "## Por supuesto q voy a medir con el Train tmb! Pero las medidas q valen son vs el test\n",
    "\n",
    "\n",
    "***\n",
    "## 2 focos en importancia de variables --> Selección de variables vs. Interpretabilidad vs. Explicabilidad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f07f31-34ec-494c-b7d3-8297b1fc13f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551bd7d5-9681-420a-859c-1bc5915b5503",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
