{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f158d0af-1b19-4573-acda-e04ed42fb59c",
   "metadata": {},
   "source": [
    "# Clase 2:\n",
    "\n",
    "- INVESTIGAR Y HACER QUE EL GITHUB **NO** sincronize los CSV, TXT y demás!\n",
    "- Es con un archivo de sincronización que diga que extenciones NO sincronizar!\n",
    "\n",
    "Recordar que siempre hay que tener activada la visión de archivos ocultos para ver todo lo que haya en los repositorios de git!\n",
    "\n",
    "OBLIGATORIO: **SIEMPRE ENTREGAR LAS PRÁCTICAS Y TODO CON README!!!**\n",
    "\n",
    "FORK GITHUB!!! LEER MEJOR\n",
    "\n",
    "# ESTRUCTURA A SEGUIR SI O SI, OBLIGATORIO PARA CUALQUIER PRÁCTICA\n",
    "\n",
    "**Seguir esto: https://drivendata.github.io/cookiecutter-data-science/ **\n",
    "\n",
    "- LICENCE\n",
    "- Makefile\n",
    "- README.md\n",
    "- CARPETA **data** **SI O SI**. Por lo menos esto. Si queremos distinguir, usamos estas:\n",
    "    - raw. El orignal.\n",
    "    - external. De 3ros.\n",
    "    - interim\n",
    "    - processed\n",
    "- docs\n",
    "- models - modelos **en formato pickle**\n",
    "- notebooks - CLAVE LA METODOLOGÍA 1_x_y. Que quede claro como leerlos / interpretarlos!\n",
    "    - DIFERENTES NOTEBOOKS, no infinitos!\n",
    "    - Secuencia de notebooks que reflejen la metodología que se sigue!\n",
    "    - VER EJEMPLOS PQ LOS NOTEBOOKS TIENEN QUE ESTÁR PERFECTA Y EXTENSAMENTE DOCUMENTADOS Y EXPLICADOS!\n",
    "    - NO se ponen en producción los Notebooks, se pasan dsps a .py y se hacen!\n",
    "    - The Data Science process. Resumen de lo que habría (ver slides):\n",
    "        - Real World problem explanation\n",
    "        - Collecting Raw Data - Explicar los datos, CADA columna, diccionarios de datos, etc. Links que lo expliquen, lo que sea. **Diccionario de datos es escencial**\n",
    "        - Data Processing - Procesamiento del tipo que sea, en donde cambio formatos, fechas, todo lo que sea cambiar los datos como los necesite, primera parte de la limpieza digamos...\n",
    "        - Clean Data - Tratamiento de nulls, outliers y demás\n",
    "        - Exploratory Data Analysis - **Escencial**, histogramas, correlaciones, dependencias parciales, TODO, un análisis super exaustivo de mis datos.\n",
    "        - Machine Learning Algorithms Statistical Models - Todos los algoritmos que vaya usando, tratamiento de variables, todo\n",
    "        - Visualización, comunicación de resultados, etc etc etc!\n",
    "        - Build Data Product\n",
    "- references\n",
    "- reports - Si tengo librerías que generen un html o algo así\n",
    "- requirements.txt - LIBRERÍAS Y VERSIONES CONCRETAS DE ESTAS!!! **OBLIGATORIO obviamente**. Se genera desde el enviroment **Y POR ESO HAY QUE TENER UN ENVIROMENT POR PROYECTO SI O SI!**. Instalar sólo lo que necesito para que funcione mi código.\n",
    "\n",
    "**CLAVE: .gitignore!**, poner todo lo que no queramos, pdf, csv, txt, etc!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae07ca5-4418-4271-b9fc-1919312cae56",
   "metadata": {},
   "source": [
    "# Explore the Data:\n",
    "\n",
    "Esto es muy importante para comenzar con cualquier modelo.\n",
    "\n",
    "TensorFlow data validation: https://www.tensorflow.org/tfx/data_validation/get_started?hl=es-419\n",
    "\n",
    "**Pandas Profiling! Herramienta clave!**. No se si es este, mirar bien: https://docs.profiling.ydata.ai/4.6/\n",
    "\n",
    "OJO con la correlacipn de las variables!\n",
    "\n",
    "SweetViz tmb mirar\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e253d44-294b-414d-8280-fc6f059f810a",
   "metadata": {},
   "source": [
    "# Práctica 0\n",
    "\n",
    "Crear env conda, python 3.9\n",
    "\n",
    "Instalar pandas, numpu\n",
    "\n",
    "UN KERNEL POR ENVIROMENT\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ab3b84-e5f9-4860-901d-2e805cff51fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3eb7a4f-05ce-4e15-803a-2e76dc4a06fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c8a45f-9d94-4ad4-9973-95cbff440631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95920fb9-696e-4829-aee3-484aa2f0cf1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb9c995-98b1-4b0f-ae81-c2e9ded65ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aabff19-6c48-4562-a8fe-f4d5ab33060d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a562e84-dd21-4464-9c50-c7cea0aa1746",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
